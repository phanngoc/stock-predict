{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use text for stock regression price prediction\n",
    "\n",
    "- https://www.kaggle.com/code/lseiyjg/use-news-to-predict-stock-markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base-v2 were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "phobert = AutoModel.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\", use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id                                     domain  \\\n",
      "0  2389  https://vneconomy.vn/kinh-te-the-gioi.htm   \n",
      "1  2390  https://vneconomy.vn/kinh-te-the-gioi.htm   \n",
      "2  2391  https://vneconomy.vn/kinh-te-the-gioi.htm   \n",
      "3  2392  https://vneconomy.vn/kinh-te-the-gioi.htm   \n",
      "4  2393  https://vneconomy.vn/kinh-te-the-gioi.htm   \n",
      "\n",
      "                                                 url  \\\n",
      "0  /tin-hieu-u-am-ve-kinh-te-toan-cau-tu-cac-nha-...   \n",
      "1  /argentina-tang-lai-suat-len-gan-70-de-chong-l...   \n",
      "2  /50-trieu-can-ho-khong-nguoi-o-qua-bom-no-cham...   \n",
      "3  /bua-tiec-trai-phieu-bat-dong-san-trung-quoc-d...   \n",
      "4  /bi-kip-thanh-cong-cua-ceo-cong-ty-duoc-menh-d...   \n",
      "\n",
      "                                               title  \\\n",
      "0  Tín hiệu u ám về kinh tế toàn cầu từ các nhà m...   \n",
      "1  Argentina tăng lãi suất lên gần 70% để chống l...   \n",
      "2  50 triệu căn hộ không người ở: “Quả bom nổ chậ...   \n",
      "3  “Bữa tiệc” trái phiếu bất động sản Trung Quốc ...   \n",
      "4  Bí kíp thành công của CEO công ty được mệnh da...   \n",
      "\n",
      "                                             content                 date  \\\n",
      "0  \\nTheo hãng tin Bloomberg, nhà sản xuất ở Trun...  2022-08-15 15:52:00   \n",
      "1  \\nNgân hàng Trung ương Argentina hôm thứ Năm t...  2022-08-15 11:43:00   \n",
      "2  \\nLiu Hong, 36 tuổi, và bố mẹ sở hữu 4 căn nhà...  2022-08-15 17:00:00   \n",
      "3  \\nKhi nhu cầu của nhà đầu tư đối với trái phiế...  2022-08-15 13:00:00   \n",
      "4  \\nHorace Luke không phải một người thích nói “...  2022-08-15 15:08:00   \n",
      "\n",
      "   tags           created_at  \n",
      "0   NaN  2023-06-11 10:31:27  \n",
      "1   NaN  2023-06-11 10:31:27  \n",
      "2   NaN  2023-06-11 10:31:27  \n",
      "3   NaN  2023-06-11 10:31:27  \n",
      "4   NaN  2023-06-11 10:31:27  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import mysql.connector\n",
    "\n",
    "# Establish a connection to the MySQL database\n",
    "connection = mysql.connector.connect(\n",
    "    host='127.0.0.1',\n",
    "    port=13306,\n",
    "    user='root',\n",
    "    password='root',\n",
    "    database='pyml'\n",
    ")\n",
    "\n",
    "# Read the table data using pandas\n",
    "query = \"SELECT title, content, date FROM crawl_data where domain = 'https://vneconomy.vn/kinh-te-the-gioi.htm'\"\n",
    "df = pd.read_sql(query, connection)\n",
    "\n",
    "# df = pd.read_csv('../../data/crawl_data_202306210731.csv')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2022-08-15\n",
      "1    2022-08-15\n",
      "2    2022-08-15\n",
      "3    2022-08-15\n",
      "4    2022-08-15\n",
      "Name: date_only, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['date_only'] = pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S').dt.strftime('%Y-%m-%d')\n",
    "print(df['date_only'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time   open   high    low  close    volume ticker        date\n",
      "0  2022-01-04  26870  28000  26740  27680  11034900    TPB  2022-01-04\n",
      "1  2022-01-05  27520  27680  27130  27190   3828100    TPB  2022-01-05\n",
      "2  2022-01-06  26740  27840  26740  27190   5190400    TPB  2022-01-06\n",
      "3  2022-01-07  27090  27450  26550  26550   4150700    TPB  2022-01-07\n",
      "4  2022-01-10  26550  27160  26190  26250   3892800    TPB  2022-01-10\n"
     ]
    }
   ],
   "source": [
    "from vnstock import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_his = stock_historical_data('TPB', '2022-01-01', '2023-07-28', \"1D\", 'stock')\n",
    "df_his['date'] = pd.to_datetime(df_his['time']).dt.strftime('%Y-%m-%d')\n",
    "print(df_his.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1498 entries, 0 to 1497\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          1498 non-null   int64  \n",
      " 1   domain      1498 non-null   object \n",
      " 2   url         1498 non-null   object \n",
      " 3   title       1498 non-null   object \n",
      " 4   content     1498 non-null   object \n",
      " 5   date        1498 non-null   object \n",
      " 6   tags        0 non-null      float64\n",
      " 7   created_at  1498 non-null   object \n",
      " 8   date_only   1498 non-null   object \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 105.5+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 391 entries, 0 to 390\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   time    391 non-null    object\n",
      " 1   open    391 non-null    int64 \n",
      " 2   high    391 non-null    int64 \n",
      " 3   low     391 non-null    int64 \n",
      " 4   close   391 non-null    int64 \n",
      " 5   volume  391 non-null    int64 \n",
      " 6   ticker  391 non-null    object\n",
      " 7   date    391 non-null    object\n",
      "dtypes: int64(5), object(3)\n",
      "memory usage: 24.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df_his.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  close      date_y\n",
      "0  Tín hiệu u ám về kinh tế toàn cầu từ các nhà m...  18740  2022-08-15\n",
      "1  Argentina tăng lãi suất lên gần 70% để chống l...  18740  2022-08-15\n",
      "2  50 triệu căn hộ không người ở: “Quả bom nổ chậ...  18740  2022-08-15\n",
      "3  “Bữa tiệc” trái phiếu bất động sản Trung Quốc ...  18740  2022-08-15\n",
      "4  Bí kíp thành công của CEO công ty được mệnh da...  18740  2022-08-15\n"
     ]
    }
   ],
   "source": [
    "dfMerge = pd.merge(df, df_his, left_on=['date_only'], right_on=['date'], how='inner')\n",
    "dfSumarize = dfMerge[['title', 'close', 'date_y']]\n",
    "print(dfSumarize.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  close      date_y\n",
      "0  Tín hiệu u ám về kinh tế toàn cầu từ các nhà m...  18740  2022-08-15\n",
      "9  Vàng sụt giá sáng đầu tuần, chuyên gia cảnh bá...  18740  2022-08-15\n",
      "8  “Đế chế” dầu lửa vùng Vịnh lãi gần 50 tỷ USD t...  18740  2022-08-15\n",
      "7  Hungary được Nga bơm nhiều khí đốt hơn, Đức lo...  18740  2022-08-15\n",
      "6  Năm công ty nhà nước Trung Quốc đồng loạt hủy ...  18740  2022-08-15\n"
     ]
    }
   ],
   "source": [
    "# Sorting the DataFrame by the 'date_column' in ascending order\n",
    "\n",
    "df_sorted = dfSumarize.sort_values(by='date_y', ascending=True)\n",
    "print(df_sorted.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-2.01829448e-02,  8.64872262e-02, -8.73286575e-02,  1.88893065e-01,\n",
      "       -1.23140261e-01, -1.68129236e-01, -2.92146027e-01, -3.38564813e-01,\n",
      "        2.12325752e-02,  1.26371041e-01,  8.35454166e-02,  5.97798750e-02,\n",
      "        1.54909700e-01,  1.58262793e-02,  5.03614135e-02, -1.22325093e-01,\n",
      "        2.16585770e-02,  2.43656784e-01, -6.98359534e-02,  2.20651329e-01,\n",
      "       -8.83912891e-02,  7.27590695e-02, -1.29440024e-01, -3.01606767e-02,\n",
      "       -3.38772833e-01,  3.08912486e-01,  1.22906407e-02,  3.96917872e-02,\n",
      "       -2.48780832e-01, -1.77071065e-01, -2.27202073e-01,  8.64247903e-02,\n",
      "        2.12022476e-02,  3.39687802e-02,  2.98975985e-02,  5.58604777e-01,\n",
      "       -1.83685452e-01,  1.48079723e-01,  1.00964420e-01,  5.66273391e-01,\n",
      "        1.44922987e-01,  1.14517875e-01,  1.71799272e-01,  1.07087240e-01,\n",
      "        2.94297278e-01, -7.76214525e-02,  2.59682566e-01,  1.10911489e-01,\n",
      "       -2.63571054e-01,  9.06947851e-02,  4.62090448e-02, -1.26314268e-01,\n",
      "       -3.54175031e-01,  3.03781062e-01,  2.45891601e-01,  8.29181597e-02,\n",
      "       -4.13582362e-02,  4.57939357e-02,  8.36575329e-02,  4.45536561e-02,\n",
      "        5.68185300e-02, -1.13015678e-02,  1.72574036e-02,  7.57216886e-02,\n",
      "        2.34913640e-02, -4.40033317e-01, -1.35522112e-01, -1.36243984e-01,\n",
      "       -1.55184165e-01,  1.48628131e-01,  1.92547083e-01, -2.99143977e-02,\n",
      "       -3.61716747e-03,  7.59465620e-02,  2.33997270e-01,  1.46899939e-01,\n",
      "       -1.21767290e-01,  1.28688484e-01, -2.09817231e-01, -1.55861443e-03,\n",
      "        1.57773331e-01,  9.59769860e-02,  2.74391860e-01,  4.77675237e-02,\n",
      "       -1.18884988e-01,  1.02762781e-01, -2.67916117e-02,  4.15534340e-02,\n",
      "        5.40292449e-02, -4.61535007e-02,  1.25824213e-01,  2.73645273e-03,\n",
      "       -4.25880484e-04,  2.39732545e-02,  9.06671733e-02,  9.19708866e-04,\n",
      "        3.66789281e-01,  1.82602443e-02,  2.36239448e-01, -6.71432391e-02,\n",
      "       -2.06767917e-02,  1.46196425e-01,  2.47283325e-01, -1.20301716e-01,\n",
      "       -8.57043639e-02,  1.93745818e-03,  1.54165506e-01, -6.69262856e-02,\n",
      "       -4.27357741e-02,  1.49960056e-01,  1.43120021e-01,  9.34974626e-02,\n",
      "       -3.67973261e-02, -1.00984812e-01,  1.27457470e-01,  1.37722805e-01,\n",
      "       -1.34860352e-01, -1.33429348e-01,  1.72730535e-01, -2.75804568e-03,\n",
      "        6.45748004e-02,  2.15516359e-01, -2.68574983e-01,  1.26881614e-01,\n",
      "        3.53615098e-02, -1.86968312e-01,  2.01809570e-01, -1.25440329e-01,\n",
      "       -4.00353894e-02, -3.76099795e-01, -2.97992408e-01, -2.75656432e-01,\n",
      "        2.28478566e-01,  2.34261885e-01,  1.16498306e-01, -2.19774637e-02,\n",
      "        1.10669047e-01,  1.35618955e-01, -3.94732878e-02,  2.01968685e-01,\n",
      "       -1.41376808e-01, -2.56958380e-02,  9.91764218e-02,  2.85457045e-01,\n",
      "        1.16900802e-01, -9.49038565e-02,  2.73955949e-02,  5.08175045e-02,\n",
      "       -4.46046144e-02,  1.13886394e-01,  1.76798642e-01, -2.65370738e-02,\n",
      "       -1.08797990e-01,  2.09107310e-01, -4.88049760e-02, -1.08082682e-01,\n",
      "        1.65231019e-01,  2.82355417e-02,  7.91224912e-02,  3.44983861e-02,\n",
      "       -7.02537671e-02,  1.69376999e-01,  3.32928061e-01,  2.14282811e-01,\n",
      "        8.96420926e-02, -1.54917210e-01,  1.11897260e-01, -1.33221992e-03,\n",
      "        7.10700974e-02,  2.33326405e-01, -1.49082720e-01, -1.08450122e-01,\n",
      "       -4.66370992e-02, -4.82092313e-02,  4.21451718e-01,  8.35777372e-02,\n",
      "       -1.70090690e-01,  1.29839286e-01, -7.31403753e-02, -1.27067074e-01,\n",
      "       -5.21340743e-02,  2.59981066e-01,  7.44373538e-03,  2.86083907e-01,\n",
      "        2.19614878e-02,  2.56032377e-01, -4.47049923e-02,  1.87600739e-02,\n",
      "       -1.32525070e-02, -1.20121920e-02,  2.05748454e-01,  6.75553977e-02,\n",
      "       -1.16207853e-01, -5.16796112e-02,  9.12423134e-02,  1.50673419e-01,\n",
      "        2.07290184e-02,  2.14189053e-01,  7.95333907e-02,  6.48753121e-02,\n",
      "        5.02312444e-02, -2.61839349e-02,  1.47623628e-01, -9.57737342e-02,\n",
      "        1.06703125e-01, -3.10374707e-01, -3.96479927e-02,  1.14713162e-01,\n",
      "        1.64308976e-02, -1.98687091e-01,  1.69604242e-01, -3.27144600e-02,\n",
      "        2.15549245e-01, -1.47837132e-01, -2.15902030e-01,  4.48432937e-02,\n",
      "        5.53212911e-02, -2.63389081e-01, -9.22248513e-02, -1.65976033e-01,\n",
      "       -4.18930613e-02,  1.71417713e-01,  5.13249710e-02,  2.19539508e-01,\n",
      "        1.23875499e-01,  2.27098867e-01,  1.91981107e-01, -1.50410399e-01,\n",
      "       -1.36223957e-01, -5.59522174e-02,  1.01780176e-01, -2.29470022e-02,\n",
      "        2.78033223e-02,  9.61841866e-02,  3.98166105e-02, -9.44505632e-02,\n",
      "       -1.04908934e-02,  4.89220619e-02,  4.63796668e-02, -9.58264396e-02,\n",
      "       -2.17795849e-01,  6.49951473e-02, -1.34481087e-01,  4.42730216e-03,\n",
      "       -1.75449908e-01,  1.31819442e-01,  1.46281242e-01,  1.68465644e-01,\n",
      "       -9.47396234e-02,  5.47500923e-02,  3.03986296e-02,  2.05188677e-01,\n",
      "        1.05953008e-01,  3.27568464e-02,  2.26490628e-02, -3.15364450e-02,\n",
      "        2.84885466e-01,  3.09936076e-01, -2.97980934e-01,  1.58355869e-02,\n",
      "       -7.48868212e-02, -9.87619236e-02,  1.26948267e-01,  1.07052580e-01,\n",
      "       -4.93960641e-02, -2.65826374e-01,  5.22458553e-01,  6.59912825e-02,\n",
      "       -7.13984296e-02,  1.36941344e-01,  1.57287970e-01,  2.10021272e-01,\n",
      "        1.29676193e-01, -1.53163582e-01, -2.45614827e-01, -1.15020804e-01,\n",
      "       -2.13466883e-02,  7.53619909e-01,  3.50918435e-02,  1.88917592e-02,\n",
      "        1.66759014e-01,  1.94608197e-01, -1.13079734e-01,  5.44409119e-02,\n",
      "        9.71382037e-02, -2.05520224e-02,  6.21333383e-02,  5.43309189e-02,\n",
      "       -1.38377566e-02, -4.99616787e-02, -7.09151030e-02, -1.46714404e-01,\n",
      "        1.03015736e-01,  2.57299393e-01, -3.94681282e-03,  5.52895725e-01,\n",
      "       -8.55949000e-02, -8.76653194e-02,  1.01546735e-01, -1.03284582e-01,\n",
      "        8.28488693e-02,  2.05491841e-01,  3.00537813e-02, -7.88722411e-02,\n",
      "       -1.67322308e-01,  2.64418535e-02,  5.45812510e-02,  1.68139532e-01,\n",
      "        4.52059776e-01, -2.05338493e-01, -1.67315397e-02, -2.12313071e-01,\n",
      "       -1.25449486e-02,  1.55440673e-01, -5.50642014e-02,  5.75314686e-02,\n",
      "       -1.94120273e-01, -1.12361657e-02,  1.60807604e-03, -2.14483529e-01,\n",
      "        7.10811466e-02, -1.24512024e-01, -1.28006309e-01, -1.24697179e-01,\n",
      "       -1.61755070e-01, -6.25666277e-03,  3.53138119e-01,  7.69923180e-02,\n",
      "       -1.10263065e-01,  1.79456137e-02,  7.46563897e-02, -5.29478816e-03,\n",
      "        1.00780934e-01,  6.48382232e-02,  3.47685465e-03,  1.23668894e-01,\n",
      "       -4.43220139e-02,  8.10727254e-02, -1.49981749e+00,  1.43469661e-01,\n",
      "        4.33769636e-02,  1.76250897e-02,  1.64815366e-01,  3.72627884e-01,\n",
      "        1.09208683e-02,  1.25948444e-01,  2.11004436e-01,  1.72644615e-01,\n",
      "       -1.28363417e-02, -8.53912458e-02, -1.02173567e-01,  9.26059037e-02,\n",
      "        3.83675247e-02,  3.10156763e-01, -1.06173024e-01, -1.46284878e-01,\n",
      "       -5.79825118e-02, -1.14765465e-02,  1.67171638e-02, -4.50791158e-02,\n",
      "        2.55247861e-01, -1.20565094e-01,  1.00472979e-01, -1.17369577e-01,\n",
      "       -2.25621596e-01,  2.69828290e-01,  1.72166556e-01,  3.75901878e-01,\n",
      "        1.23076625e-02,  1.48459449e-01, -1.00876004e-01,  1.39805630e-01,\n",
      "       -1.35728493e-01, -1.66442186e-01, -2.45673001e-01, -1.27584308e-01,\n",
      "       -1.89811029e-02,  6.80391788e-02, -3.92208472e-02,  2.26713821e-01,\n",
      "       -9.92388055e-02,  1.10205337e-01,  1.21047892e-01,  1.67710990e-01,\n",
      "       -1.04408264e-01,  3.04867998e-02,  5.33682434e-03, -1.68337032e-01,\n",
      "        3.18738937e-01,  1.39907002e-01,  9.78643149e-02,  2.43506089e-01,\n",
      "       -6.29460290e-02,  1.85938989e-04,  3.41031072e-03,  6.55527264e-02,\n",
      "        2.28626862e-01,  4.72968444e-02, -7.72165805e-02,  6.13336749e-02,\n",
      "        4.47407424e-01,  1.70970336e-01,  1.59512032e-02, -8.11629221e-02,\n",
      "        1.25505269e-01, -8.00576061e-02, -1.21525370e-01,  7.45356530e-02,\n",
      "       -5.09020835e-02, -1.16709955e-01, -2.69043803e-01,  1.38188452e-01,\n",
      "        1.11842342e-01,  8.95729065e-02,  6.29860833e-02, -4.23584357e-02,\n",
      "       -1.58949524e-01,  1.15782218e-02,  1.75197572e-01, -7.50219449e-02,\n",
      "       -2.12747958e-02, -1.27153531e-01,  9.61113498e-02, -4.72117402e-02,\n",
      "        1.64996549e-01,  3.08777660e-01,  4.56165001e-02,  1.71576843e-01,\n",
      "        5.03238179e-02,  4.51670215e-02,  1.51600569e-01, -2.21510395e-01,\n",
      "        1.31191120e-01, -8.53338614e-02,  1.30579740e-01,  1.44936308e-01,\n",
      "       -9.33254659e-02, -6.60349280e-02, -8.37875530e-03, -1.77891389e-01,\n",
      "        1.35388836e-01,  1.10008083e-01,  5.85574144e-03,  1.70544475e-01,\n",
      "       -3.78965139e-02,  3.89549136e-02,  1.72424316e-01,  1.27806261e-01,\n",
      "        5.22534437e-02, -1.93789795e-01, -8.88504907e-02,  1.92800447e-01,\n",
      "       -5.79944886e-02,  5.69106527e-02,  2.73131505e-02,  1.43878087e-01,\n",
      "        9.05771106e-02,  1.76183119e-01, -1.19439706e-01, -2.41404235e-01,\n",
      "       -9.54839401e-03,  5.08090891e-02,  8.37818440e-03, -9.35455114e-02,\n",
      "        1.07786380e-01,  6.29636198e-02,  1.24209411e-01,  3.19570273e-01,\n",
      "       -1.49955645e-01,  1.68003559e-01, -6.78312406e-02,  2.96437740e-02,\n",
      "       -6.75836205e-03, -2.70824358e-02, -3.46293189e-02, -6.69919774e-02,\n",
      "        5.37486710e-02, -6.15750477e-02,  8.95275921e-02,  4.75588351e-01,\n",
      "        4.95424084e-02, -1.67331975e-02,  1.67929634e-01,  1.20808342e-02,\n",
      "       -1.27174795e-01,  5.39143123e-02, -4.99862358e-02,  8.20936784e-02,\n",
      "        3.10208350e-01,  1.96274534e-01, -7.74101466e-02, -1.18594542e-01,\n",
      "       -1.74993947e-02,  2.45503392e-02, -1.43897474e-01,  2.23189220e-01,\n",
      "        4.11277078e-02,  5.58544695e-03,  6.59038269e-05,  8.40993375e-02,\n",
      "       -4.32522371e-02, -2.01500934e-02,  1.70834944e-01,  6.90542981e-02,\n",
      "        9.00248215e-02,  1.88859969e-01, -1.24323822e-03,  5.91598898e-02,\n",
      "       -4.11755703e-02, -6.82020709e-02,  1.97505444e-01, -3.43084455e-01,\n",
      "       -9.04379040e-02,  1.87651128e-01, -1.17418379e-01,  1.92068473e-01,\n",
      "       -4.95143980e-02,  1.73647255e-01, -2.50152797e-01, -1.04318604e-01,\n",
      "        2.23401874e-01,  3.20853293e-03,  1.89827934e-01, -2.07729816e-01,\n",
      "       -1.69910282e-01, -1.56028658e-01,  3.45395150e-04,  1.82906806e-01,\n",
      "        9.32759345e-02,  4.39719707e-02, -2.07419395e-01,  3.31028044e-01,\n",
      "        3.53142142e-01,  2.65689909e-01,  1.85375601e-01, -1.93300962e-01,\n",
      "        6.60159290e-02,  6.59799725e-02,  2.73774654e-01, -2.49409769e-02,\n",
      "        1.01790860e-01,  1.03166498e-01, -1.43981233e-01, -4.35535349e-02,\n",
      "       -2.47303396e-01,  1.44139513e-01,  4.33063060e-01,  2.04713985e-01,\n",
      "        2.58069709e-02, -4.03650433e-01, -1.46547988e-01,  1.57785676e-02,\n",
      "        1.01408139e-01,  7.34091327e-02, -1.00572623e-01,  6.05031699e-02,\n",
      "        1.46771416e-01,  1.60359934e-01,  9.72334892e-02, -1.68919697e-01,\n",
      "        1.16128474e-01, -3.93659808e-02, -3.32234763e-02, -2.59097349e-02,\n",
      "       -3.30769539e-01, -3.04730743e-01,  6.99693412e-02,  6.14929833e-02,\n",
      "        2.49471202e-01,  3.42747420e-01,  3.27818953e-02,  5.02194837e-02,\n",
      "        1.36468261e-01, -7.10274372e-03, -2.62890667e-01,  1.21531887e-02,\n",
      "        3.12362872e-02,  7.42041916e-02,  2.32791349e-01, -1.34882137e-01,\n",
      "       -7.82312155e-02, -5.16256616e-02, -2.83057392e-02, -2.09578961e-01,\n",
      "        1.42280132e-01, -3.34055945e-02,  9.17553902e-02, -1.02880828e-01,\n",
      "       -1.51714414e-01,  2.16934904e-01,  1.33769679e+00, -2.55939245e-01,\n",
      "        8.40257853e-02, -1.45376652e-01,  1.70151055e-01,  2.27839142e-01,\n",
      "        1.95205733e-02,  1.14553288e-01, -7.09508359e-02,  8.02592859e-02,\n",
      "        2.96927482e-01,  2.10904390e-01,  1.03217833e-01,  2.52222449e-01,\n",
      "        1.10506192e-01,  5.37782721e-02,  1.86421931e-01,  1.42666087e-01,\n",
      "       -1.54875919e-01,  7.83311043e-05, -7.71944672e-02,  2.65574940e-02,\n",
      "        4.53977399e-02,  4.71877865e-02,  7.65934065e-02, -1.30007759e-01,\n",
      "        3.46512720e-02,  7.62375295e-02,  1.21336512e-01, -1.44821256e-01,\n",
      "       -7.50298873e-02,  2.72041917e-01, -9.64856893e-02,  1.65387869e-01,\n",
      "       -3.34843271e-03, -2.98596602e-02, -4.62898824e-05,  8.93799588e-02,\n",
      "       -7.05399662e-02,  6.02174811e-02, -4.06103320e-02, -3.39288890e-01,\n",
      "       -2.79610679e-02,  1.83191046e-01,  2.03703985e-01, -2.48985693e-01,\n",
      "        2.49426141e-01,  1.44738972e-01, -1.44996807e-01,  7.84037113e-02,\n",
      "       -7.48176873e-02,  3.68463933e-01, -9.87390149e-03, -2.04634205e-01,\n",
      "        1.57959703e-02,  2.35206604e-01,  7.00468272e-02, -2.43252143e-02,\n",
      "       -6.01453967e-02, -1.28611937e-01,  2.87474077e-02,  1.47125751e-01,\n",
      "       -9.29012969e-02, -2.43400231e-01,  9.56693515e-02, -1.63050622e-01,\n",
      "        2.17357397e-01, -1.98308483e-01,  2.74822079e-02,  2.02418253e-01,\n",
      "       -1.92837775e-01,  4.50102538e-02, -4.35035154e-02,  2.77681768e-01,\n",
      "       -1.27230743e-02, -1.45456225e-01,  1.83843728e-02,  1.60953440e-02,\n",
      "       -1.89402848e-01,  1.40856117e-01, -8.17223173e-03,  1.66475475e-01,\n",
      "       -4.44358960e-02,  2.31994644e-01,  2.60196537e-01, -1.41218409e-01,\n",
      "       -1.10360965e-01,  8.52559060e-02,  8.03273767e-02,  9.88357216e-02,\n",
      "        2.59157330e-01,  9.25763994e-02,  1.16476584e-02,  2.99669236e-01,\n",
      "       -7.51085952e-02,  1.21939577e-01,  1.06580488e-01,  4.12273370e-02,\n",
      "        4.00275499e-01, -2.02670515e-01, -1.51383325e-01,  4.77750488e-02,\n",
      "       -4.57805954e-02, -8.59841853e-02,  9.67683736e-03,  8.73291939e-02,\n",
      "       -1.06352799e-01,  1.74581349e-01, -7.54384100e-02,  1.20168738e-01,\n",
      "        3.02139908e-01,  2.03573242e-01,  3.14987183e-01,  1.16225943e-01,\n",
      "       -2.20643625e-01, -8.02746639e-02,  1.11031458e-01,  1.31619081e-01,\n",
      "        5.09100892e-02,  4.87872101e-02,  7.03834370e-02, -8.15731380e-03,\n",
      "       -1.59507409e-01,  3.07775550e-02,  7.80704916e-02, -2.76055157e-01,\n",
      "       -1.06273666e-01,  2.15005875e-01, -2.74960488e-01,  8.85831639e-02,\n",
      "       -1.29769221e-01, -4.99655269e-02, -7.93478116e-02, -1.75688893e-01,\n",
      "        4.04012054e-02, -7.17687160e-02,  3.81139815e-01, -8.76472443e-02,\n",
      "       -2.29629263e-01,  3.14654559e-01, -9.52518508e-02, -1.10957675e-01,\n",
      "        1.02380551e-01, -6.00021519e-02,  1.32714629e-01, -7.23706966e-04,\n",
      "        1.41043201e-01,  6.45603910e-02, -1.16451740e-01,  9.67975557e-02,\n",
      "        3.59490246e-01, -8.37618038e-02,  3.39005023e-01, -5.52089885e-02,\n",
      "       -9.01477709e-02,  9.94512290e-02,  1.61922842e-01, -1.25411808e-01,\n",
      "       -2.22193718e-01,  1.76176697e-01,  4.03846335e-03,  1.40754670e-01,\n",
      "       -1.46789756e-02, -1.46623533e-02, -3.08257733e-02, -1.04186267e-01,\n",
      "       -4.02131304e-02,  2.13334665e-01, -2.93889999e-01,  1.44197956e-01,\n",
      "        3.52459680e-03, -7.19227921e-03,  3.29437293e-02, -1.28473975e-02,\n",
      "        2.46914998e-02, -5.66931702e-02,  2.54559010e-01,  1.92316204e-01],\n",
      "      dtype=float32)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/37kt02914kx36yzcbbqfyck00000gn/T/ipykernel_3844/3106091539.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddedTitle = phobert(torch.tensor(encodedTextInputIds))\n"
     ]
    }
   ],
   "source": [
    "from nis import cat\n",
    "from exceptiongroup import catch\n",
    "from torch import embedding\n",
    "from torch.nn.functional import pad\n",
    "from underthesea import classify, word_tokenize, sent_tokenize\n",
    "from pickle import load\n",
    "\n",
    "max_len = 258\n",
    "\n",
    "def extract_hidden_state(outputs, type='view'):\n",
    "    # 2 way for get hidden state: outputs[0], outputs['last_hidden_state']\n",
    "    with torch.no_grad():\n",
    "        if type == 'view':\n",
    "            hiddenSize = outputs[0].size()[0]\n",
    "            # flatten dimension 1 and 2, and hold batch dimension 0\n",
    "            embeddings = outputs[0].view(hiddenSize, -1).numpy()\n",
    "        elif type == 'mean':\n",
    "            hiddenSize = outputs[0].size()[0]\n",
    "            embeddings = outputs[0].mean(axis=1).numpy()\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def vectorize_mean(sentences, type_extract='mean'):\n",
    "    encodedText = tokenizer.batch_encode_plus(\n",
    "        sentences,\n",
    "        add_special_tokens=True,\n",
    "        truncation=True, \n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=False,\n",
    "        max_length=max_len, return_tensors='pt'\n",
    "        )\n",
    "    encodedTextInputIds = encodedText['input_ids']\n",
    "    embeddedTitle = phobert(torch.tensor(encodedTextInputIds))\n",
    "    embedding = extract_hidden_state(embeddedTitle, type_extract)\n",
    "    return embedding\n",
    "\n",
    "def vectorize_mean_for(sentences, type_extract='mean'):\n",
    "    embeddingArr = []\n",
    "    for sentence in sentences:\n",
    "        try:\n",
    "            encodedText = tokenizer.encode_plus(\n",
    "                sentence, padding=True, truncation=True, \n",
    "                add_special_tokens=True,\n",
    "                return_attention_mask=True,\n",
    "                max_length=300, return_tensors='pt')\n",
    "        except Exception as e:\n",
    "            print('e', e, sentence)\n",
    "            return None\n",
    "        \n",
    "        encodedTextInputIds = encodedText['input_ids']\n",
    "        embeddedTitle = phobert(torch.tensor(encodedTextInputIds))\n",
    "        embedding = extract_hidden_state(embeddedTitle, type_extract)\n",
    "        embeddingArr.append(embedding.ravel())\n",
    "    return embeddingArr\n",
    "\n",
    "def trim_words(sentence, num_word=200):\n",
    "    # Split the sentence into words\n",
    "    words = sentence.split()\n",
    "    # Trim the sentence to 5 words\n",
    "    trimmed_sentence = \" \".join(words[:num_word])\n",
    "    return trimmed_sentence\n",
    "\n",
    "\n",
    "test = [\n",
    "    'Lạm phát khiến Hàn Quốc giảm ngân sách lần đầu',\n",
    "]\n",
    "\n",
    "# t = vectorize_mean(test)\n",
    "t = vectorize_mean_for(test)\n",
    "print(t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/37kt02914kx36yzcbbqfyck00000gn/T/ipykernel_3844/3106091539.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddedTitle = phobert(torch.tensor(encodedTextInputIds))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1323, 768)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "x_train_raw = df_sorted['title'].values.tolist()\n",
    "\n",
    "x_train = vectorize_mean_for(x_train_raw, type_extract='mean')\n",
    "\n",
    "print(np.array(x_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 768) [18740 18740 18740 18740 18740 18740 18740 18740 18740 18740]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVR(kernel='linear')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train_raw = df_sorted['close'][:10]\n",
    "y_train = y_train_raw[:10].ravel()\n",
    "x_train_t = x_train[:10]\n",
    "print(x_train_t.shape, y_train)\n",
    "# Step 2: Create and fit the SVR model\n",
    "modelSvg = SVR(kernel='linear')\n",
    "modelSvg.fit(x_train_t, y_train)  # ravel y_train to convert to 1D array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 [array([-2.01829448e-02,  8.64872262e-02, -8.73286575e-02,  1.88893065e-01,\n",
      "       -1.23140261e-01, -1.68129236e-01, -2.92146027e-01, -3.38564813e-01,\n",
      "        2.12325752e-02,  1.26371041e-01,  8.35454166e-02,  5.97798750e-02,\n",
      "        1.54909700e-01,  1.58262793e-02,  5.03614135e-02, -1.22325093e-01,\n",
      "        2.16585770e-02,  2.43656784e-01, -6.98359534e-02,  2.20651329e-01,\n",
      "       -8.83912891e-02,  7.27590695e-02, -1.29440024e-01, -3.01606767e-02,\n",
      "       -3.38772833e-01,  3.08912486e-01,  1.22906407e-02,  3.96917872e-02,\n",
      "       -2.48780832e-01, -1.77071065e-01, -2.27202073e-01,  8.64247903e-02,\n",
      "        2.12022476e-02,  3.39687802e-02,  2.98975985e-02,  5.58604777e-01,\n",
      "       -1.83685452e-01,  1.48079723e-01,  1.00964420e-01,  5.66273391e-01,\n",
      "        1.44922987e-01,  1.14517875e-01,  1.71799272e-01,  1.07087240e-01,\n",
      "        2.94297278e-01, -7.76214525e-02,  2.59682566e-01,  1.10911489e-01,\n",
      "       -2.63571054e-01,  9.06947851e-02,  4.62090448e-02, -1.26314268e-01,\n",
      "       -3.54175031e-01,  3.03781062e-01,  2.45891601e-01,  8.29181597e-02,\n",
      "       -4.13582362e-02,  4.57939357e-02,  8.36575329e-02,  4.45536561e-02,\n",
      "        5.68185300e-02, -1.13015678e-02,  1.72574036e-02,  7.57216886e-02,\n",
      "        2.34913640e-02, -4.40033317e-01, -1.35522112e-01, -1.36243984e-01,\n",
      "       -1.55184165e-01,  1.48628131e-01,  1.92547083e-01, -2.99143977e-02,\n",
      "       -3.61716747e-03,  7.59465620e-02,  2.33997270e-01,  1.46899939e-01,\n",
      "       -1.21767290e-01,  1.28688484e-01, -2.09817231e-01, -1.55861443e-03,\n",
      "        1.57773331e-01,  9.59769860e-02,  2.74391860e-01,  4.77675237e-02,\n",
      "       -1.18884988e-01,  1.02762781e-01, -2.67916117e-02,  4.15534340e-02,\n",
      "        5.40292449e-02, -4.61535007e-02,  1.25824213e-01,  2.73645273e-03,\n",
      "       -4.25880484e-04,  2.39732545e-02,  9.06671733e-02,  9.19708866e-04,\n",
      "        3.66789281e-01,  1.82602443e-02,  2.36239448e-01, -6.71432391e-02,\n",
      "       -2.06767917e-02,  1.46196425e-01,  2.47283325e-01, -1.20301716e-01,\n",
      "       -8.57043639e-02,  1.93745818e-03,  1.54165506e-01, -6.69262856e-02,\n",
      "       -4.27357741e-02,  1.49960056e-01,  1.43120021e-01,  9.34974626e-02,\n",
      "       -3.67973261e-02, -1.00984812e-01,  1.27457470e-01,  1.37722805e-01,\n",
      "       -1.34860352e-01, -1.33429348e-01,  1.72730535e-01, -2.75804568e-03,\n",
      "        6.45748004e-02,  2.15516359e-01, -2.68574983e-01,  1.26881614e-01,\n",
      "        3.53615098e-02, -1.86968312e-01,  2.01809570e-01, -1.25440329e-01,\n",
      "       -4.00353894e-02, -3.76099795e-01, -2.97992408e-01, -2.75656432e-01,\n",
      "        2.28478566e-01,  2.34261885e-01,  1.16498306e-01, -2.19774637e-02,\n",
      "        1.10669047e-01,  1.35618955e-01, -3.94732878e-02,  2.01968685e-01,\n",
      "       -1.41376808e-01, -2.56958380e-02,  9.91764218e-02,  2.85457045e-01,\n",
      "        1.16900802e-01, -9.49038565e-02,  2.73955949e-02,  5.08175045e-02,\n",
      "       -4.46046144e-02,  1.13886394e-01,  1.76798642e-01, -2.65370738e-02,\n",
      "       -1.08797990e-01,  2.09107310e-01, -4.88049760e-02, -1.08082682e-01,\n",
      "        1.65231019e-01,  2.82355417e-02,  7.91224912e-02,  3.44983861e-02,\n",
      "       -7.02537671e-02,  1.69376999e-01,  3.32928061e-01,  2.14282811e-01,\n",
      "        8.96420926e-02, -1.54917210e-01,  1.11897260e-01, -1.33221992e-03,\n",
      "        7.10700974e-02,  2.33326405e-01, -1.49082720e-01, -1.08450122e-01,\n",
      "       -4.66370992e-02, -4.82092313e-02,  4.21451718e-01,  8.35777372e-02,\n",
      "       -1.70090690e-01,  1.29839286e-01, -7.31403753e-02, -1.27067074e-01,\n",
      "       -5.21340743e-02,  2.59981066e-01,  7.44373538e-03,  2.86083907e-01,\n",
      "        2.19614878e-02,  2.56032377e-01, -4.47049923e-02,  1.87600739e-02,\n",
      "       -1.32525070e-02, -1.20121920e-02,  2.05748454e-01,  6.75553977e-02,\n",
      "       -1.16207853e-01, -5.16796112e-02,  9.12423134e-02,  1.50673419e-01,\n",
      "        2.07290184e-02,  2.14189053e-01,  7.95333907e-02,  6.48753121e-02,\n",
      "        5.02312444e-02, -2.61839349e-02,  1.47623628e-01, -9.57737342e-02,\n",
      "        1.06703125e-01, -3.10374707e-01, -3.96479927e-02,  1.14713162e-01,\n",
      "        1.64308976e-02, -1.98687091e-01,  1.69604242e-01, -3.27144600e-02,\n",
      "        2.15549245e-01, -1.47837132e-01, -2.15902030e-01,  4.48432937e-02,\n",
      "        5.53212911e-02, -2.63389081e-01, -9.22248513e-02, -1.65976033e-01,\n",
      "       -4.18930613e-02,  1.71417713e-01,  5.13249710e-02,  2.19539508e-01,\n",
      "        1.23875499e-01,  2.27098867e-01,  1.91981107e-01, -1.50410399e-01,\n",
      "       -1.36223957e-01, -5.59522174e-02,  1.01780176e-01, -2.29470022e-02,\n",
      "        2.78033223e-02,  9.61841866e-02,  3.98166105e-02, -9.44505632e-02,\n",
      "       -1.04908934e-02,  4.89220619e-02,  4.63796668e-02, -9.58264396e-02,\n",
      "       -2.17795849e-01,  6.49951473e-02, -1.34481087e-01,  4.42730216e-03,\n",
      "       -1.75449908e-01,  1.31819442e-01,  1.46281242e-01,  1.68465644e-01,\n",
      "       -9.47396234e-02,  5.47500923e-02,  3.03986296e-02,  2.05188677e-01,\n",
      "        1.05953008e-01,  3.27568464e-02,  2.26490628e-02, -3.15364450e-02,\n",
      "        2.84885466e-01,  3.09936076e-01, -2.97980934e-01,  1.58355869e-02,\n",
      "       -7.48868212e-02, -9.87619236e-02,  1.26948267e-01,  1.07052580e-01,\n",
      "       -4.93960641e-02, -2.65826374e-01,  5.22458553e-01,  6.59912825e-02,\n",
      "       -7.13984296e-02,  1.36941344e-01,  1.57287970e-01,  2.10021272e-01,\n",
      "        1.29676193e-01, -1.53163582e-01, -2.45614827e-01, -1.15020804e-01,\n",
      "       -2.13466883e-02,  7.53619909e-01,  3.50918435e-02,  1.88917592e-02,\n",
      "        1.66759014e-01,  1.94608197e-01, -1.13079734e-01,  5.44409119e-02,\n",
      "        9.71382037e-02, -2.05520224e-02,  6.21333383e-02,  5.43309189e-02,\n",
      "       -1.38377566e-02, -4.99616787e-02, -7.09151030e-02, -1.46714404e-01,\n",
      "        1.03015736e-01,  2.57299393e-01, -3.94681282e-03,  5.52895725e-01,\n",
      "       -8.55949000e-02, -8.76653194e-02,  1.01546735e-01, -1.03284582e-01,\n",
      "        8.28488693e-02,  2.05491841e-01,  3.00537813e-02, -7.88722411e-02,\n",
      "       -1.67322308e-01,  2.64418535e-02,  5.45812510e-02,  1.68139532e-01,\n",
      "        4.52059776e-01, -2.05338493e-01, -1.67315397e-02, -2.12313071e-01,\n",
      "       -1.25449486e-02,  1.55440673e-01, -5.50642014e-02,  5.75314686e-02,\n",
      "       -1.94120273e-01, -1.12361657e-02,  1.60807604e-03, -2.14483529e-01,\n",
      "        7.10811466e-02, -1.24512024e-01, -1.28006309e-01, -1.24697179e-01,\n",
      "       -1.61755070e-01, -6.25666277e-03,  3.53138119e-01,  7.69923180e-02,\n",
      "       -1.10263065e-01,  1.79456137e-02,  7.46563897e-02, -5.29478816e-03,\n",
      "        1.00780934e-01,  6.48382232e-02,  3.47685465e-03,  1.23668894e-01,\n",
      "       -4.43220139e-02,  8.10727254e-02, -1.49981749e+00,  1.43469661e-01,\n",
      "        4.33769636e-02,  1.76250897e-02,  1.64815366e-01,  3.72627884e-01,\n",
      "        1.09208683e-02,  1.25948444e-01,  2.11004436e-01,  1.72644615e-01,\n",
      "       -1.28363417e-02, -8.53912458e-02, -1.02173567e-01,  9.26059037e-02,\n",
      "        3.83675247e-02,  3.10156763e-01, -1.06173024e-01, -1.46284878e-01,\n",
      "       -5.79825118e-02, -1.14765465e-02,  1.67171638e-02, -4.50791158e-02,\n",
      "        2.55247861e-01, -1.20565094e-01,  1.00472979e-01, -1.17369577e-01,\n",
      "       -2.25621596e-01,  2.69828290e-01,  1.72166556e-01,  3.75901878e-01,\n",
      "        1.23076625e-02,  1.48459449e-01, -1.00876004e-01,  1.39805630e-01,\n",
      "       -1.35728493e-01, -1.66442186e-01, -2.45673001e-01, -1.27584308e-01,\n",
      "       -1.89811029e-02,  6.80391788e-02, -3.92208472e-02,  2.26713821e-01,\n",
      "       -9.92388055e-02,  1.10205337e-01,  1.21047892e-01,  1.67710990e-01,\n",
      "       -1.04408264e-01,  3.04867998e-02,  5.33682434e-03, -1.68337032e-01,\n",
      "        3.18738937e-01,  1.39907002e-01,  9.78643149e-02,  2.43506089e-01,\n",
      "       -6.29460290e-02,  1.85938989e-04,  3.41031072e-03,  6.55527264e-02,\n",
      "        2.28626862e-01,  4.72968444e-02, -7.72165805e-02,  6.13336749e-02,\n",
      "        4.47407424e-01,  1.70970336e-01,  1.59512032e-02, -8.11629221e-02,\n",
      "        1.25505269e-01, -8.00576061e-02, -1.21525370e-01,  7.45356530e-02,\n",
      "       -5.09020835e-02, -1.16709955e-01, -2.69043803e-01,  1.38188452e-01,\n",
      "        1.11842342e-01,  8.95729065e-02,  6.29860833e-02, -4.23584357e-02,\n",
      "       -1.58949524e-01,  1.15782218e-02,  1.75197572e-01, -7.50219449e-02,\n",
      "       -2.12747958e-02, -1.27153531e-01,  9.61113498e-02, -4.72117402e-02,\n",
      "        1.64996549e-01,  3.08777660e-01,  4.56165001e-02,  1.71576843e-01,\n",
      "        5.03238179e-02,  4.51670215e-02,  1.51600569e-01, -2.21510395e-01,\n",
      "        1.31191120e-01, -8.53338614e-02,  1.30579740e-01,  1.44936308e-01,\n",
      "       -9.33254659e-02, -6.60349280e-02, -8.37875530e-03, -1.77891389e-01,\n",
      "        1.35388836e-01,  1.10008083e-01,  5.85574144e-03,  1.70544475e-01,\n",
      "       -3.78965139e-02,  3.89549136e-02,  1.72424316e-01,  1.27806261e-01,\n",
      "        5.22534437e-02, -1.93789795e-01, -8.88504907e-02,  1.92800447e-01,\n",
      "       -5.79944886e-02,  5.69106527e-02,  2.73131505e-02,  1.43878087e-01,\n",
      "        9.05771106e-02,  1.76183119e-01, -1.19439706e-01, -2.41404235e-01,\n",
      "       -9.54839401e-03,  5.08090891e-02,  8.37818440e-03, -9.35455114e-02,\n",
      "        1.07786380e-01,  6.29636198e-02,  1.24209411e-01,  3.19570273e-01,\n",
      "       -1.49955645e-01,  1.68003559e-01, -6.78312406e-02,  2.96437740e-02,\n",
      "       -6.75836205e-03, -2.70824358e-02, -3.46293189e-02, -6.69919774e-02,\n",
      "        5.37486710e-02, -6.15750477e-02,  8.95275921e-02,  4.75588351e-01,\n",
      "        4.95424084e-02, -1.67331975e-02,  1.67929634e-01,  1.20808342e-02,\n",
      "       -1.27174795e-01,  5.39143123e-02, -4.99862358e-02,  8.20936784e-02,\n",
      "        3.10208350e-01,  1.96274534e-01, -7.74101466e-02, -1.18594542e-01,\n",
      "       -1.74993947e-02,  2.45503392e-02, -1.43897474e-01,  2.23189220e-01,\n",
      "        4.11277078e-02,  5.58544695e-03,  6.59038269e-05,  8.40993375e-02,\n",
      "       -4.32522371e-02, -2.01500934e-02,  1.70834944e-01,  6.90542981e-02,\n",
      "        9.00248215e-02,  1.88859969e-01, -1.24323822e-03,  5.91598898e-02,\n",
      "       -4.11755703e-02, -6.82020709e-02,  1.97505444e-01, -3.43084455e-01,\n",
      "       -9.04379040e-02,  1.87651128e-01, -1.17418379e-01,  1.92068473e-01,\n",
      "       -4.95143980e-02,  1.73647255e-01, -2.50152797e-01, -1.04318604e-01,\n",
      "        2.23401874e-01,  3.20853293e-03,  1.89827934e-01, -2.07729816e-01,\n",
      "       -1.69910282e-01, -1.56028658e-01,  3.45395150e-04,  1.82906806e-01,\n",
      "        9.32759345e-02,  4.39719707e-02, -2.07419395e-01,  3.31028044e-01,\n",
      "        3.53142142e-01,  2.65689909e-01,  1.85375601e-01, -1.93300962e-01,\n",
      "        6.60159290e-02,  6.59799725e-02,  2.73774654e-01, -2.49409769e-02,\n",
      "        1.01790860e-01,  1.03166498e-01, -1.43981233e-01, -4.35535349e-02,\n",
      "       -2.47303396e-01,  1.44139513e-01,  4.33063060e-01,  2.04713985e-01,\n",
      "        2.58069709e-02, -4.03650433e-01, -1.46547988e-01,  1.57785676e-02,\n",
      "        1.01408139e-01,  7.34091327e-02, -1.00572623e-01,  6.05031699e-02,\n",
      "        1.46771416e-01,  1.60359934e-01,  9.72334892e-02, -1.68919697e-01,\n",
      "        1.16128474e-01, -3.93659808e-02, -3.32234763e-02, -2.59097349e-02,\n",
      "       -3.30769539e-01, -3.04730743e-01,  6.99693412e-02,  6.14929833e-02,\n",
      "        2.49471202e-01,  3.42747420e-01,  3.27818953e-02,  5.02194837e-02,\n",
      "        1.36468261e-01, -7.10274372e-03, -2.62890667e-01,  1.21531887e-02,\n",
      "        3.12362872e-02,  7.42041916e-02,  2.32791349e-01, -1.34882137e-01,\n",
      "       -7.82312155e-02, -5.16256616e-02, -2.83057392e-02, -2.09578961e-01,\n",
      "        1.42280132e-01, -3.34055945e-02,  9.17553902e-02, -1.02880828e-01,\n",
      "       -1.51714414e-01,  2.16934904e-01,  1.33769679e+00, -2.55939245e-01,\n",
      "        8.40257853e-02, -1.45376652e-01,  1.70151055e-01,  2.27839142e-01,\n",
      "        1.95205733e-02,  1.14553288e-01, -7.09508359e-02,  8.02592859e-02,\n",
      "        2.96927482e-01,  2.10904390e-01,  1.03217833e-01,  2.52222449e-01,\n",
      "        1.10506192e-01,  5.37782721e-02,  1.86421931e-01,  1.42666087e-01,\n",
      "       -1.54875919e-01,  7.83311043e-05, -7.71944672e-02,  2.65574940e-02,\n",
      "        4.53977399e-02,  4.71877865e-02,  7.65934065e-02, -1.30007759e-01,\n",
      "        3.46512720e-02,  7.62375295e-02,  1.21336512e-01, -1.44821256e-01,\n",
      "       -7.50298873e-02,  2.72041917e-01, -9.64856893e-02,  1.65387869e-01,\n",
      "       -3.34843271e-03, -2.98596602e-02, -4.62898824e-05,  8.93799588e-02,\n",
      "       -7.05399662e-02,  6.02174811e-02, -4.06103320e-02, -3.39288890e-01,\n",
      "       -2.79610679e-02,  1.83191046e-01,  2.03703985e-01, -2.48985693e-01,\n",
      "        2.49426141e-01,  1.44738972e-01, -1.44996807e-01,  7.84037113e-02,\n",
      "       -7.48176873e-02,  3.68463933e-01, -9.87390149e-03, -2.04634205e-01,\n",
      "        1.57959703e-02,  2.35206604e-01,  7.00468272e-02, -2.43252143e-02,\n",
      "       -6.01453967e-02, -1.28611937e-01,  2.87474077e-02,  1.47125751e-01,\n",
      "       -9.29012969e-02, -2.43400231e-01,  9.56693515e-02, -1.63050622e-01,\n",
      "        2.17357397e-01, -1.98308483e-01,  2.74822079e-02,  2.02418253e-01,\n",
      "       -1.92837775e-01,  4.50102538e-02, -4.35035154e-02,  2.77681768e-01,\n",
      "       -1.27230743e-02, -1.45456225e-01,  1.83843728e-02,  1.60953440e-02,\n",
      "       -1.89402848e-01,  1.40856117e-01, -8.17223173e-03,  1.66475475e-01,\n",
      "       -4.44358960e-02,  2.31994644e-01,  2.60196537e-01, -1.41218409e-01,\n",
      "       -1.10360965e-01,  8.52559060e-02,  8.03273767e-02,  9.88357216e-02,\n",
      "        2.59157330e-01,  9.25763994e-02,  1.16476584e-02,  2.99669236e-01,\n",
      "       -7.51085952e-02,  1.21939577e-01,  1.06580488e-01,  4.12273370e-02,\n",
      "        4.00275499e-01, -2.02670515e-01, -1.51383325e-01,  4.77750488e-02,\n",
      "       -4.57805954e-02, -8.59841853e-02,  9.67683736e-03,  8.73291939e-02,\n",
      "       -1.06352799e-01,  1.74581349e-01, -7.54384100e-02,  1.20168738e-01,\n",
      "        3.02139908e-01,  2.03573242e-01,  3.14987183e-01,  1.16225943e-01,\n",
      "       -2.20643625e-01, -8.02746639e-02,  1.11031458e-01,  1.31619081e-01,\n",
      "        5.09100892e-02,  4.87872101e-02,  7.03834370e-02, -8.15731380e-03,\n",
      "       -1.59507409e-01,  3.07775550e-02,  7.80704916e-02, -2.76055157e-01,\n",
      "       -1.06273666e-01,  2.15005875e-01, -2.74960488e-01,  8.85831639e-02,\n",
      "       -1.29769221e-01, -4.99655269e-02, -7.93478116e-02, -1.75688893e-01,\n",
      "        4.04012054e-02, -7.17687160e-02,  3.81139815e-01, -8.76472443e-02,\n",
      "       -2.29629263e-01,  3.14654559e-01, -9.52518508e-02, -1.10957675e-01,\n",
      "        1.02380551e-01, -6.00021519e-02,  1.32714629e-01, -7.23706966e-04,\n",
      "        1.41043201e-01,  6.45603910e-02, -1.16451740e-01,  9.67975557e-02,\n",
      "        3.59490246e-01, -8.37618038e-02,  3.39005023e-01, -5.52089885e-02,\n",
      "       -9.01477709e-02,  9.94512290e-02,  1.61922842e-01, -1.25411808e-01,\n",
      "       -2.22193718e-01,  1.76176697e-01,  4.03846335e-03,  1.40754670e-01,\n",
      "       -1.46789756e-02, -1.46623533e-02, -3.08257733e-02, -1.04186267e-01,\n",
      "       -4.02131304e-02,  2.13334665e-01, -2.93889999e-01,  1.44197956e-01,\n",
      "        3.52459680e-03, -7.19227921e-03,  3.29437293e-02, -1.28473975e-02,\n",
      "        2.46914998e-02, -5.66931702e-02,  2.54559010e-01,  1.92316204e-01],\n",
      "      dtype=float32)]\n",
      "[15715.31322234]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/37kt02914kx36yzcbbqfyck00000gn/T/ipykernel_3844/3106091539.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddedTitle = phobert(torch.tensor(encodedTextInputIds))\n"
     ]
    }
   ],
   "source": [
    "test = [\n",
    "    'Lạm phát khiến Hàn Quốc giảm ngân sách lần đầu',\n",
    "]\n",
    "\n",
    "# t = vectorize_mean(test)\n",
    "x_test_encoded = vectorize_mean_for(test)\n",
    "print(len(x_test_encoded[0]), x_test_encoded)\n",
    "result_pred = modelSvg.predict(x_test_encoded)\n",
    "print(result_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10, 15, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 256)               196864    \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 229,889\n",
      "Trainable params: 229,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda, Embedding, LSTM, SimpleRNN, GRU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "input_dim = x_train.shape[1]\n",
    "nb_classes = 1\n",
    "# Here's a Deep Dumb MLP (DDMLP)\n",
    "modelDL = Sequential()\n",
    "modelDL.add(Dense(256, input_dim=input_dim))\n",
    "modelDL.add(Activation('relu'))\n",
    "modelDL.add(Dropout(0.4))\n",
    "modelDL.add(Dense(128))\n",
    "modelDL.add(Activation('relu'))\n",
    "modelDL.add(Dropout(0.4))\n",
    "modelDL.add(Dense(nb_classes))\n",
    "modelDL.add(Activation('softmax'))\n",
    "modelDL.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(modelDL.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b069ada0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelDL.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
