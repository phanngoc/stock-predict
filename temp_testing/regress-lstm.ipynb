{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use text for stock regression price prediction\n",
    "\n",
    "- https://www.kaggle.com/code/lseiyjg/use-news-to-predict-stock-markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base-v2 were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "phobert = AutoModel.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\", use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/37kt02914kx36yzcbbqfyck00000gn/T/ipykernel_66269/2159884431.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title  close      date_y\n",
      "1257  Lo sợ lĩnh vực công nghiệp sụp đổ, châu Âu “vã...  14470  2022-10-07\n",
      "1252  Lợi nhuận của Samsung giảm mạnh do nhu cầu chi...  14470  2022-10-07\n",
      "1253  Giá vàng thế giới giảm, trong nước đồng loạt t...  14470  2022-10-07\n",
      "1256      10 nhà sản xuất pin xe điện hàng đầu thế giới  14470  2022-10-07\n",
      "1255  Chứng khoán Mỹ tiếp tục lao dốc, giá dầu giữ đ...  14470  2022-10-07\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import mysql.connector\n",
    "\n",
    "# Establish a connection to the MySQL database\n",
    "connection = mysql.connector.connect(\n",
    "    host='127.0.0.1',\n",
    "    port=13306,\n",
    "    user='root',\n",
    "    password='root',\n",
    "    database='pyml'\n",
    ")\n",
    "\n",
    "# Read the table data using pandas\n",
    "query = \"SELECT title, content, date FROM crawl_data where domain = 'https://vneconomy.vn/kinh-te-the-gioi.htm'\"\n",
    "df = pd.read_sql(query, connection)\n",
    "\n",
    "df['date_only'] = pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "from vnstock import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_his = stock_historical_data('TPB', '2022-01-01', '2023-07-28', \"1D\", 'stock')\n",
    "df_his['date'] = pd.to_datetime(df_his['time']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "dfMerge = pd.merge(df, df_his, left_on=['date_only'], right_on=['date'], how='inner')\n",
    "dfSumarize = dfMerge[['title', 'close', 'date_y']]\n",
    "\n",
    "# Sorting the DataFrame by the 'date_column' in ascending order\n",
    "\n",
    "df_sorted = dfSumarize.sort_values(by='date_y', ascending=True)\n",
    "print(df_sorted.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit (1258,) (1258,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ngocp/Documents/projects/pyml/stock/temp_testing/../algorithm/regress.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddedTitle = self.model(torch.tensor(encodedTextInputIds))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_1: [14470 14470 14470 ... 18700 18700 18700]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../algorithm')\n",
    "import regress\n",
    "from importlib import reload\n",
    "reload(regress)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "modelClass = regress.PhobertTransform(phobert, tokenizer)\n",
    "\n",
    "x_train_raw = df_sorted['title']\n",
    "y_train_raw = df_sorted['close']\n",
    "\n",
    "modelClass.fit(x_train_raw, y_train_raw)\n",
    "\n",
    "# print(np.array(x_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15694.28574872]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ngocp/Documents/projects/pyml/stock/temp_testing/../algorithm/regress.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddedTitle = self.model(torch.tensor(encodedTextInputIds))\n"
     ]
    }
   ],
   "source": [
    "test = [\n",
    "    'Lạm phát khiến Hàn Quốc giảm ngân sách lần đầu',\n",
    "]\n",
    "\n",
    "# t = vectorize_mean(test)\n",
    "t = modelClass.predict(test)\n",
    "print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 [array([-2.01829448e-02,  8.64872262e-02, -8.73286575e-02,  1.88893065e-01,\n",
      "       -1.23140261e-01, -1.68129236e-01, -2.92146027e-01, -3.38564813e-01,\n",
      "        2.12325752e-02,  1.26371041e-01,  8.35454166e-02,  5.97798750e-02,\n",
      "        1.54909700e-01,  1.58262793e-02,  5.03614135e-02, -1.22325093e-01,\n",
      "        2.16585770e-02,  2.43656784e-01, -6.98359534e-02,  2.20651329e-01,\n",
      "       -8.83912891e-02,  7.27590695e-02, -1.29440024e-01, -3.01606767e-02,\n",
      "       -3.38772833e-01,  3.08912486e-01,  1.22906407e-02,  3.96917872e-02,\n",
      "       -2.48780832e-01, -1.77071065e-01, -2.27202073e-01,  8.64247903e-02,\n",
      "        2.12022476e-02,  3.39687802e-02,  2.98975985e-02,  5.58604777e-01,\n",
      "       -1.83685452e-01,  1.48079723e-01,  1.00964420e-01,  5.66273391e-01,\n",
      "        1.44922987e-01,  1.14517875e-01,  1.71799272e-01,  1.07087240e-01,\n",
      "        2.94297278e-01, -7.76214525e-02,  2.59682566e-01,  1.10911489e-01,\n",
      "       -2.63571054e-01,  9.06947851e-02,  4.62090448e-02, -1.26314268e-01,\n",
      "       -3.54175031e-01,  3.03781062e-01,  2.45891601e-01,  8.29181597e-02,\n",
      "       -4.13582362e-02,  4.57939357e-02,  8.36575329e-02,  4.45536561e-02,\n",
      "        5.68185300e-02, -1.13015678e-02,  1.72574036e-02,  7.57216886e-02,\n",
      "        2.34913640e-02, -4.40033317e-01, -1.35522112e-01, -1.36243984e-01,\n",
      "       -1.55184165e-01,  1.48628131e-01,  1.92547083e-01, -2.99143977e-02,\n",
      "       -3.61716747e-03,  7.59465620e-02,  2.33997270e-01,  1.46899939e-01,\n",
      "       -1.21767290e-01,  1.28688484e-01, -2.09817231e-01, -1.55861443e-03,\n",
      "        1.57773331e-01,  9.59769860e-02,  2.74391860e-01,  4.77675237e-02,\n",
      "       -1.18884988e-01,  1.02762781e-01, -2.67916117e-02,  4.15534340e-02,\n",
      "        5.40292449e-02, -4.61535007e-02,  1.25824213e-01,  2.73645273e-03,\n",
      "       -4.25880484e-04,  2.39732545e-02,  9.06671733e-02,  9.19708866e-04,\n",
      "        3.66789281e-01,  1.82602443e-02,  2.36239448e-01, -6.71432391e-02,\n",
      "       -2.06767917e-02,  1.46196425e-01,  2.47283325e-01, -1.20301716e-01,\n",
      "       -8.57043639e-02,  1.93745818e-03,  1.54165506e-01, -6.69262856e-02,\n",
      "       -4.27357741e-02,  1.49960056e-01,  1.43120021e-01,  9.34974626e-02,\n",
      "       -3.67973261e-02, -1.00984812e-01,  1.27457470e-01,  1.37722805e-01,\n",
      "       -1.34860352e-01, -1.33429348e-01,  1.72730535e-01, -2.75804568e-03,\n",
      "        6.45748004e-02,  2.15516359e-01, -2.68574983e-01,  1.26881614e-01,\n",
      "        3.53615098e-02, -1.86968312e-01,  2.01809570e-01, -1.25440329e-01,\n",
      "       -4.00353894e-02, -3.76099795e-01, -2.97992408e-01, -2.75656432e-01,\n",
      "        2.28478566e-01,  2.34261885e-01,  1.16498306e-01, -2.19774637e-02,\n",
      "        1.10669047e-01,  1.35618955e-01, -3.94732878e-02,  2.01968685e-01,\n",
      "       -1.41376808e-01, -2.56958380e-02,  9.91764218e-02,  2.85457045e-01,\n",
      "        1.16900802e-01, -9.49038565e-02,  2.73955949e-02,  5.08175045e-02,\n",
      "       -4.46046144e-02,  1.13886394e-01,  1.76798642e-01, -2.65370738e-02,\n",
      "       -1.08797990e-01,  2.09107310e-01, -4.88049760e-02, -1.08082682e-01,\n",
      "        1.65231019e-01,  2.82355417e-02,  7.91224912e-02,  3.44983861e-02,\n",
      "       -7.02537671e-02,  1.69376999e-01,  3.32928061e-01,  2.14282811e-01,\n",
      "        8.96420926e-02, -1.54917210e-01,  1.11897260e-01, -1.33221992e-03,\n",
      "        7.10700974e-02,  2.33326405e-01, -1.49082720e-01, -1.08450122e-01,\n",
      "       -4.66370992e-02, -4.82092313e-02,  4.21451718e-01,  8.35777372e-02,\n",
      "       -1.70090690e-01,  1.29839286e-01, -7.31403753e-02, -1.27067074e-01,\n",
      "       -5.21340743e-02,  2.59981066e-01,  7.44373538e-03,  2.86083907e-01,\n",
      "        2.19614878e-02,  2.56032377e-01, -4.47049923e-02,  1.87600739e-02,\n",
      "       -1.32525070e-02, -1.20121920e-02,  2.05748454e-01,  6.75553977e-02,\n",
      "       -1.16207853e-01, -5.16796112e-02,  9.12423134e-02,  1.50673419e-01,\n",
      "        2.07290184e-02,  2.14189053e-01,  7.95333907e-02,  6.48753121e-02,\n",
      "        5.02312444e-02, -2.61839349e-02,  1.47623628e-01, -9.57737342e-02,\n",
      "        1.06703125e-01, -3.10374707e-01, -3.96479927e-02,  1.14713162e-01,\n",
      "        1.64308976e-02, -1.98687091e-01,  1.69604242e-01, -3.27144600e-02,\n",
      "        2.15549245e-01, -1.47837132e-01, -2.15902030e-01,  4.48432937e-02,\n",
      "        5.53212911e-02, -2.63389081e-01, -9.22248513e-02, -1.65976033e-01,\n",
      "       -4.18930613e-02,  1.71417713e-01,  5.13249710e-02,  2.19539508e-01,\n",
      "        1.23875499e-01,  2.27098867e-01,  1.91981107e-01, -1.50410399e-01,\n",
      "       -1.36223957e-01, -5.59522174e-02,  1.01780176e-01, -2.29470022e-02,\n",
      "        2.78033223e-02,  9.61841866e-02,  3.98166105e-02, -9.44505632e-02,\n",
      "       -1.04908934e-02,  4.89220619e-02,  4.63796668e-02, -9.58264396e-02,\n",
      "       -2.17795849e-01,  6.49951473e-02, -1.34481087e-01,  4.42730216e-03,\n",
      "       -1.75449908e-01,  1.31819442e-01,  1.46281242e-01,  1.68465644e-01,\n",
      "       -9.47396234e-02,  5.47500923e-02,  3.03986296e-02,  2.05188677e-01,\n",
      "        1.05953008e-01,  3.27568464e-02,  2.26490628e-02, -3.15364450e-02,\n",
      "        2.84885466e-01,  3.09936076e-01, -2.97980934e-01,  1.58355869e-02,\n",
      "       -7.48868212e-02, -9.87619236e-02,  1.26948267e-01,  1.07052580e-01,\n",
      "       -4.93960641e-02, -2.65826374e-01,  5.22458553e-01,  6.59912825e-02,\n",
      "       -7.13984296e-02,  1.36941344e-01,  1.57287970e-01,  2.10021272e-01,\n",
      "        1.29676193e-01, -1.53163582e-01, -2.45614827e-01, -1.15020804e-01,\n",
      "       -2.13466883e-02,  7.53619909e-01,  3.50918435e-02,  1.88917592e-02,\n",
      "        1.66759014e-01,  1.94608197e-01, -1.13079734e-01,  5.44409119e-02,\n",
      "        9.71382037e-02, -2.05520224e-02,  6.21333383e-02,  5.43309189e-02,\n",
      "       -1.38377566e-02, -4.99616787e-02, -7.09151030e-02, -1.46714404e-01,\n",
      "        1.03015736e-01,  2.57299393e-01, -3.94681282e-03,  5.52895725e-01,\n",
      "       -8.55949000e-02, -8.76653194e-02,  1.01546735e-01, -1.03284582e-01,\n",
      "        8.28488693e-02,  2.05491841e-01,  3.00537813e-02, -7.88722411e-02,\n",
      "       -1.67322308e-01,  2.64418535e-02,  5.45812510e-02,  1.68139532e-01,\n",
      "        4.52059776e-01, -2.05338493e-01, -1.67315397e-02, -2.12313071e-01,\n",
      "       -1.25449486e-02,  1.55440673e-01, -5.50642014e-02,  5.75314686e-02,\n",
      "       -1.94120273e-01, -1.12361657e-02,  1.60807604e-03, -2.14483529e-01,\n",
      "        7.10811466e-02, -1.24512024e-01, -1.28006309e-01, -1.24697179e-01,\n",
      "       -1.61755070e-01, -6.25666277e-03,  3.53138119e-01,  7.69923180e-02,\n",
      "       -1.10263065e-01,  1.79456137e-02,  7.46563897e-02, -5.29478816e-03,\n",
      "        1.00780934e-01,  6.48382232e-02,  3.47685465e-03,  1.23668894e-01,\n",
      "       -4.43220139e-02,  8.10727254e-02, -1.49981749e+00,  1.43469661e-01,\n",
      "        4.33769636e-02,  1.76250897e-02,  1.64815366e-01,  3.72627884e-01,\n",
      "        1.09208683e-02,  1.25948444e-01,  2.11004436e-01,  1.72644615e-01,\n",
      "       -1.28363417e-02, -8.53912458e-02, -1.02173567e-01,  9.26059037e-02,\n",
      "        3.83675247e-02,  3.10156763e-01, -1.06173024e-01, -1.46284878e-01,\n",
      "       -5.79825118e-02, -1.14765465e-02,  1.67171638e-02, -4.50791158e-02,\n",
      "        2.55247861e-01, -1.20565094e-01,  1.00472979e-01, -1.17369577e-01,\n",
      "       -2.25621596e-01,  2.69828290e-01,  1.72166556e-01,  3.75901878e-01,\n",
      "        1.23076625e-02,  1.48459449e-01, -1.00876004e-01,  1.39805630e-01,\n",
      "       -1.35728493e-01, -1.66442186e-01, -2.45673001e-01, -1.27584308e-01,\n",
      "       -1.89811029e-02,  6.80391788e-02, -3.92208472e-02,  2.26713821e-01,\n",
      "       -9.92388055e-02,  1.10205337e-01,  1.21047892e-01,  1.67710990e-01,\n",
      "       -1.04408264e-01,  3.04867998e-02,  5.33682434e-03, -1.68337032e-01,\n",
      "        3.18738937e-01,  1.39907002e-01,  9.78643149e-02,  2.43506089e-01,\n",
      "       -6.29460290e-02,  1.85938989e-04,  3.41031072e-03,  6.55527264e-02,\n",
      "        2.28626862e-01,  4.72968444e-02, -7.72165805e-02,  6.13336749e-02,\n",
      "        4.47407424e-01,  1.70970336e-01,  1.59512032e-02, -8.11629221e-02,\n",
      "        1.25505269e-01, -8.00576061e-02, -1.21525370e-01,  7.45356530e-02,\n",
      "       -5.09020835e-02, -1.16709955e-01, -2.69043803e-01,  1.38188452e-01,\n",
      "        1.11842342e-01,  8.95729065e-02,  6.29860833e-02, -4.23584357e-02,\n",
      "       -1.58949524e-01,  1.15782218e-02,  1.75197572e-01, -7.50219449e-02,\n",
      "       -2.12747958e-02, -1.27153531e-01,  9.61113498e-02, -4.72117402e-02,\n",
      "        1.64996549e-01,  3.08777660e-01,  4.56165001e-02,  1.71576843e-01,\n",
      "        5.03238179e-02,  4.51670215e-02,  1.51600569e-01, -2.21510395e-01,\n",
      "        1.31191120e-01, -8.53338614e-02,  1.30579740e-01,  1.44936308e-01,\n",
      "       -9.33254659e-02, -6.60349280e-02, -8.37875530e-03, -1.77891389e-01,\n",
      "        1.35388836e-01,  1.10008083e-01,  5.85574144e-03,  1.70544475e-01,\n",
      "       -3.78965139e-02,  3.89549136e-02,  1.72424316e-01,  1.27806261e-01,\n",
      "        5.22534437e-02, -1.93789795e-01, -8.88504907e-02,  1.92800447e-01,\n",
      "       -5.79944886e-02,  5.69106527e-02,  2.73131505e-02,  1.43878087e-01,\n",
      "        9.05771106e-02,  1.76183119e-01, -1.19439706e-01, -2.41404235e-01,\n",
      "       -9.54839401e-03,  5.08090891e-02,  8.37818440e-03, -9.35455114e-02,\n",
      "        1.07786380e-01,  6.29636198e-02,  1.24209411e-01,  3.19570273e-01,\n",
      "       -1.49955645e-01,  1.68003559e-01, -6.78312406e-02,  2.96437740e-02,\n",
      "       -6.75836205e-03, -2.70824358e-02, -3.46293189e-02, -6.69919774e-02,\n",
      "        5.37486710e-02, -6.15750477e-02,  8.95275921e-02,  4.75588351e-01,\n",
      "        4.95424084e-02, -1.67331975e-02,  1.67929634e-01,  1.20808342e-02,\n",
      "       -1.27174795e-01,  5.39143123e-02, -4.99862358e-02,  8.20936784e-02,\n",
      "        3.10208350e-01,  1.96274534e-01, -7.74101466e-02, -1.18594542e-01,\n",
      "       -1.74993947e-02,  2.45503392e-02, -1.43897474e-01,  2.23189220e-01,\n",
      "        4.11277078e-02,  5.58544695e-03,  6.59038269e-05,  8.40993375e-02,\n",
      "       -4.32522371e-02, -2.01500934e-02,  1.70834944e-01,  6.90542981e-02,\n",
      "        9.00248215e-02,  1.88859969e-01, -1.24323822e-03,  5.91598898e-02,\n",
      "       -4.11755703e-02, -6.82020709e-02,  1.97505444e-01, -3.43084455e-01,\n",
      "       -9.04379040e-02,  1.87651128e-01, -1.17418379e-01,  1.92068473e-01,\n",
      "       -4.95143980e-02,  1.73647255e-01, -2.50152797e-01, -1.04318604e-01,\n",
      "        2.23401874e-01,  3.20853293e-03,  1.89827934e-01, -2.07729816e-01,\n",
      "       -1.69910282e-01, -1.56028658e-01,  3.45395150e-04,  1.82906806e-01,\n",
      "        9.32759345e-02,  4.39719707e-02, -2.07419395e-01,  3.31028044e-01,\n",
      "        3.53142142e-01,  2.65689909e-01,  1.85375601e-01, -1.93300962e-01,\n",
      "        6.60159290e-02,  6.59799725e-02,  2.73774654e-01, -2.49409769e-02,\n",
      "        1.01790860e-01,  1.03166498e-01, -1.43981233e-01, -4.35535349e-02,\n",
      "       -2.47303396e-01,  1.44139513e-01,  4.33063060e-01,  2.04713985e-01,\n",
      "        2.58069709e-02, -4.03650433e-01, -1.46547988e-01,  1.57785676e-02,\n",
      "        1.01408139e-01,  7.34091327e-02, -1.00572623e-01,  6.05031699e-02,\n",
      "        1.46771416e-01,  1.60359934e-01,  9.72334892e-02, -1.68919697e-01,\n",
      "        1.16128474e-01, -3.93659808e-02, -3.32234763e-02, -2.59097349e-02,\n",
      "       -3.30769539e-01, -3.04730743e-01,  6.99693412e-02,  6.14929833e-02,\n",
      "        2.49471202e-01,  3.42747420e-01,  3.27818953e-02,  5.02194837e-02,\n",
      "        1.36468261e-01, -7.10274372e-03, -2.62890667e-01,  1.21531887e-02,\n",
      "        3.12362872e-02,  7.42041916e-02,  2.32791349e-01, -1.34882137e-01,\n",
      "       -7.82312155e-02, -5.16256616e-02, -2.83057392e-02, -2.09578961e-01,\n",
      "        1.42280132e-01, -3.34055945e-02,  9.17553902e-02, -1.02880828e-01,\n",
      "       -1.51714414e-01,  2.16934904e-01,  1.33769679e+00, -2.55939245e-01,\n",
      "        8.40257853e-02, -1.45376652e-01,  1.70151055e-01,  2.27839142e-01,\n",
      "        1.95205733e-02,  1.14553288e-01, -7.09508359e-02,  8.02592859e-02,\n",
      "        2.96927482e-01,  2.10904390e-01,  1.03217833e-01,  2.52222449e-01,\n",
      "        1.10506192e-01,  5.37782721e-02,  1.86421931e-01,  1.42666087e-01,\n",
      "       -1.54875919e-01,  7.83311043e-05, -7.71944672e-02,  2.65574940e-02,\n",
      "        4.53977399e-02,  4.71877865e-02,  7.65934065e-02, -1.30007759e-01,\n",
      "        3.46512720e-02,  7.62375295e-02,  1.21336512e-01, -1.44821256e-01,\n",
      "       -7.50298873e-02,  2.72041917e-01, -9.64856893e-02,  1.65387869e-01,\n",
      "       -3.34843271e-03, -2.98596602e-02, -4.62898824e-05,  8.93799588e-02,\n",
      "       -7.05399662e-02,  6.02174811e-02, -4.06103320e-02, -3.39288890e-01,\n",
      "       -2.79610679e-02,  1.83191046e-01,  2.03703985e-01, -2.48985693e-01,\n",
      "        2.49426141e-01,  1.44738972e-01, -1.44996807e-01,  7.84037113e-02,\n",
      "       -7.48176873e-02,  3.68463933e-01, -9.87390149e-03, -2.04634205e-01,\n",
      "        1.57959703e-02,  2.35206604e-01,  7.00468272e-02, -2.43252143e-02,\n",
      "       -6.01453967e-02, -1.28611937e-01,  2.87474077e-02,  1.47125751e-01,\n",
      "       -9.29012969e-02, -2.43400231e-01,  9.56693515e-02, -1.63050622e-01,\n",
      "        2.17357397e-01, -1.98308483e-01,  2.74822079e-02,  2.02418253e-01,\n",
      "       -1.92837775e-01,  4.50102538e-02, -4.35035154e-02,  2.77681768e-01,\n",
      "       -1.27230743e-02, -1.45456225e-01,  1.83843728e-02,  1.60953440e-02,\n",
      "       -1.89402848e-01,  1.40856117e-01, -8.17223173e-03,  1.66475475e-01,\n",
      "       -4.44358960e-02,  2.31994644e-01,  2.60196537e-01, -1.41218409e-01,\n",
      "       -1.10360965e-01,  8.52559060e-02,  8.03273767e-02,  9.88357216e-02,\n",
      "        2.59157330e-01,  9.25763994e-02,  1.16476584e-02,  2.99669236e-01,\n",
      "       -7.51085952e-02,  1.21939577e-01,  1.06580488e-01,  4.12273370e-02,\n",
      "        4.00275499e-01, -2.02670515e-01, -1.51383325e-01,  4.77750488e-02,\n",
      "       -4.57805954e-02, -8.59841853e-02,  9.67683736e-03,  8.73291939e-02,\n",
      "       -1.06352799e-01,  1.74581349e-01, -7.54384100e-02,  1.20168738e-01,\n",
      "        3.02139908e-01,  2.03573242e-01,  3.14987183e-01,  1.16225943e-01,\n",
      "       -2.20643625e-01, -8.02746639e-02,  1.11031458e-01,  1.31619081e-01,\n",
      "        5.09100892e-02,  4.87872101e-02,  7.03834370e-02, -8.15731380e-03,\n",
      "       -1.59507409e-01,  3.07775550e-02,  7.80704916e-02, -2.76055157e-01,\n",
      "       -1.06273666e-01,  2.15005875e-01, -2.74960488e-01,  8.85831639e-02,\n",
      "       -1.29769221e-01, -4.99655269e-02, -7.93478116e-02, -1.75688893e-01,\n",
      "        4.04012054e-02, -7.17687160e-02,  3.81139815e-01, -8.76472443e-02,\n",
      "       -2.29629263e-01,  3.14654559e-01, -9.52518508e-02, -1.10957675e-01,\n",
      "        1.02380551e-01, -6.00021519e-02,  1.32714629e-01, -7.23706966e-04,\n",
      "        1.41043201e-01,  6.45603910e-02, -1.16451740e-01,  9.67975557e-02,\n",
      "        3.59490246e-01, -8.37618038e-02,  3.39005023e-01, -5.52089885e-02,\n",
      "       -9.01477709e-02,  9.94512290e-02,  1.61922842e-01, -1.25411808e-01,\n",
      "       -2.22193718e-01,  1.76176697e-01,  4.03846335e-03,  1.40754670e-01,\n",
      "       -1.46789756e-02, -1.46623533e-02, -3.08257733e-02, -1.04186267e-01,\n",
      "       -4.02131304e-02,  2.13334665e-01, -2.93889999e-01,  1.44197956e-01,\n",
      "        3.52459680e-03, -7.19227921e-03,  3.29437293e-02, -1.28473975e-02,\n",
      "        2.46914998e-02, -5.66931702e-02,  2.54559010e-01,  1.92316204e-01],\n",
      "      dtype=float32)]\n",
      "[15715.31322234]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/37kt02914kx36yzcbbqfyck00000gn/T/ipykernel_3844/3106091539.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddedTitle = phobert(torch.tensor(encodedTextInputIds))\n"
     ]
    }
   ],
   "source": [
    "test = [\n",
    "    'Lạm phát khiến Hàn Quốc giảm ngân sách lần đầu',\n",
    "]\n",
    "\n",
    "# t = vectorize_mean(test)\n",
    "x_test_encoded = vectorize_mean_for(test)\n",
    "print(len(x_test_encoded[0]), x_test_encoded)\n",
    "result_pred = modelSvg.predict(x_test_encoded)\n",
    "print(result_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10, 15, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 256)               196864    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 229,889\n",
      "Trainable params: 229,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda, Embedding, LSTM, SimpleRNN, GRU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "input_dim = x_train.shape[1]\n",
    "nb_classes = 1\n",
    "# Here's a Deep Dumb MLP (DDMLP)\n",
    "modelDL = Sequential()\n",
    "modelDL.add(Dense(256, input_dim=input_dim))\n",
    "modelDL.add(Activation('relu'))\n",
    "modelDL.add(Dropout(0.4))\n",
    "modelDL.add(Dense(128))\n",
    "modelDL.add(Activation('relu'))\n",
    "modelDL.add(Dropout(0.4))\n",
    "modelDL.add(Dense(nb_classes))\n",
    "modelDL.add(Activation('softmax'))\n",
    "modelDL.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(modelDL.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d0643fd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelDL.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
