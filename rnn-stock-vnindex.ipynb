{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thử dùng RNN cho predict stock VNINDEX \n",
    "- Dựa trên notebook: https://www.kaggle.com/code/lequidon/google-stock-price-prediction-rnn/edit\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Ngày  Lần cuối        Mở       Cao      Thấp       KL % Thay đổi\n",
      "377  01/12/2021  1,485.19  1,478.44  1,487.68  1,471.30  876.73K      0.46%\n",
      "376  02/12/2021  1,482.05  1,485.19  1,493.84  1,482.05  763.96K     -0.21%\n",
      "375  03/12/2021  1,443.32  1,482.05  1,491.20  1,443.32    1.10M     -2.61%\n",
      "374  06/12/2021  1,413.58  1,443.32  1,452.55  1,400.87    1.04M     -2.06%\n",
      "373  07/12/2021  1,446.77  1,413.58  1,446.77  1,413.58  755.91K      2.35%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset_train = pd.read_csv(\"./data/vn_index.csv\")\n",
    "dataset_train = dataset_train.iloc[::-1]\n",
    "print(dataset_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Ngày  Lần cuối        Mở       Cao      Thấp       KL % Thay đổi\n",
      "377  01/12/2021   1485.19  1,478.44  1,487.68  1,471.30  876.73K      0.46%\n",
      "376  02/12/2021   1482.05  1,485.19  1,493.84  1,482.05  763.96K     -0.21%\n",
      "375  03/12/2021   1443.32  1,482.05  1,491.20  1,443.32    1.10M     -2.61%\n",
      "374  06/12/2021   1413.58  1,443.32  1,452.55  1,400.87    1.04M     -2.06%\n",
      "373  07/12/2021   1446.77  1,413.58  1,446.77  1,413.58  755.91K      2.35%\n"
     ]
    }
   ],
   "source": [
    "dataset_train['Lần cuối'] = dataset_train['Lần cuối'].apply(lambda x: float(x.replace(',','')))\n",
    "print(dataset_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1485.19]\n",
      " [1482.05]\n",
      " [1443.32]\n",
      " [1413.58]\n",
      " [1446.77]\n",
      " [1452.87]\n",
      " [1467.98]\n",
      " [1463.54]\n",
      " [1476.21]\n",
      " [1476.02]\n",
      " [1475.5 ]\n",
      " [1476.61]\n",
      " [1479.79]\n",
      " [1477.33]\n",
      " [1478.74]\n",
      " [1477.67]\n",
      " [1456.96]\n",
      " [1477.03]\n",
      " [1488.88]\n",
      " [1494.39]\n",
      " [1485.82]\n",
      " [1485.97]\n",
      " [1498.28]\n",
      " [1525.58]\n",
      " [1522.5 ]\n",
      " [1528.57]\n",
      " [1528.48]\n",
      " [1503.71]\n",
      " [1492.31]\n",
      " [1510.51]\n",
      " [1496.05]\n",
      " [1496.02]\n",
      " [1452.84]\n",
      " [1438.94]\n",
      " [1442.79]\n",
      " [1465.3 ]\n",
      " [1472.89]\n",
      " [1439.71]\n",
      " [1479.58]\n",
      " [1481.58]\n",
      " [1470.76]\n",
      " [1478.96]\n",
      " [1497.66]\n",
      " [1500.99]\n",
      " [1505.38]\n",
      " [1506.79]\n",
      " [1501.71]\n",
      " [1471.96]\n",
      " [1492.75]\n",
      " [1492.1 ]\n",
      " [1507.99]\n",
      " [1504.84]\n",
      " [1510.84]\n",
      " [1503.47]\n",
      " [1512.3 ]\n",
      " [1494.85]\n",
      " [1498.89]\n",
      " [1490.13]\n",
      " [1498.78]\n",
      " [1485.52]\n",
      " [1505.  ]\n",
      " [1505.33]\n",
      " [1499.05]\n",
      " [1473.71]\n",
      " [1473.74]\n",
      " [1479.08]\n",
      " [1466.54]\n",
      " [1446.25]\n",
      " [1452.74]\n",
      " [1459.33]\n",
      " [1461.34]\n",
      " [1469.1 ]\n",
      " [1494.95]\n",
      " [1503.78]\n",
      " [1502.34]\n",
      " [1498.26]\n",
      " [1498.5 ]\n",
      " [1483.18]\n",
      " [1497.76]\n",
      " [1490.51]\n",
      " [1492.15]\n",
      " [1516.44]\n",
      " [1524.7 ]\n",
      " [1520.03]\n",
      " [1522.9 ]\n",
      " [1502.35]\n",
      " [1482.  ]\n",
      " [1455.25]\n",
      " [1477.2 ]\n",
      " [1472.12]\n",
      " [1458.56]\n",
      " [1432.6 ]\n",
      " [1406.45]\n",
      " [1384.72]\n",
      " [1370.21]\n",
      " [1379.23]\n",
      " [1310.92]\n",
      " [1341.34]\n",
      " [1353.77]\n",
      " [1350.99]\n",
      " [1366.8 ]\n",
      " [1348.68]\n",
      " [1360.68]\n",
      " [1329.26]\n",
      " [1269.62]\n",
      " [1293.56]\n",
      " [1301.53]\n",
      " [1238.84]\n",
      " [1182.77]\n",
      " [1171.95]\n",
      " [1228.37]\n",
      " [1240.76]\n",
      " [1241.64]\n",
      " [1240.71]\n",
      " [1218.81]\n",
      " [1233.38]\n",
      " [1268.43]\n",
      " [1268.57]\n",
      " [1285.45]\n",
      " [1293.92]\n",
      " [1292.68]\n",
      " [1299.52]\n",
      " [1288.62]\n",
      " [1287.98]\n",
      " [1290.01]\n",
      " [1291.35]\n",
      " [1307.91]\n",
      " [1307.8 ]\n",
      " [1284.08]\n",
      " [1227.04]\n",
      " [1230.31]\n",
      " [1213.93]\n",
      " [1236.63]\n",
      " [1217.3 ]\n",
      " [1180.4 ]\n",
      " [1172.47]\n",
      " [1169.27]\n",
      " [1188.88]\n",
      " [1185.48]\n",
      " [1202.82]\n",
      " [1218.1 ]\n",
      " [1218.09]\n",
      " [1197.6 ]\n",
      " [1198.9 ]\n",
      " [1195.53]\n",
      " [1181.29]\n",
      " [1149.61]\n",
      " [1166.48]\n",
      " [1171.31]\n",
      " [1155.29]\n",
      " [1174.82]\n",
      " [1173.92]\n",
      " [1182.17]\n",
      " [1179.25]\n",
      " [1176.49]\n",
      " [1178.33]\n",
      " [1194.14]\n",
      " [1198.47]\n",
      " [1194.76]\n",
      " [1188.5 ]\n",
      " [1185.07]\n",
      " [1191.04]\n",
      " [1208.12]\n",
      " [1206.33]\n",
      " [1231.35]\n",
      " [1241.62]\n",
      " [1249.76]\n",
      " [1254.15]\n",
      " [1252.74]\n",
      " [1256.75]\n",
      " [1258.85]\n",
      " [1256.5 ]\n",
      " [1252.07]\n",
      " [1262.33]\n",
      " [1274.2 ]\n",
      " [1274.69]\n",
      " [1275.28]\n",
      " [1273.66]\n",
      " [1269.18]\n",
      " [1260.43]\n",
      " [1270.81]\n",
      " [1277.16]\n",
      " [1288.88]\n",
      " [1282.57]\n",
      " [1270.8 ]\n",
      " [1279.39]\n",
      " [1280.51]\n",
      " [1277.35]\n",
      " [1277.4 ]\n",
      " [1243.17]\n",
      " [1234.6 ]\n",
      " [1248.78]\n",
      " [1249.62]\n",
      " [1248.4 ]\n",
      " [1240.77]\n",
      " [1245.66]\n",
      " [1234.03]\n",
      " [1205.43]\n",
      " [1218.93]\n",
      " [1210.55]\n",
      " [1214.7 ]\n",
      " [1203.28]\n",
      " [1174.35]\n",
      " [1166.54]\n",
      " [1143.62]\n",
      " [1126.07]\n",
      " [1132.11]\n",
      " [1086.44]\n",
      " [1078.14]\n",
      " [1104.26]\n",
      " [1074.52]\n",
      " [1035.91]\n",
      " [1042.48]\n",
      " [1006.2 ]\n",
      " [1034.81]\n",
      " [1050.99]\n",
      " [1061.85]\n",
      " [1051.58]\n",
      " [1063.66]\n",
      " [1060.07]\n",
      " [1058.45]\n",
      " [1019.82]\n",
      " [ 986.15]\n",
      " [ 997.7 ]\n",
      " [ 993.36]\n",
      " [1028.01]\n",
      " [1027.36]\n",
      " [1027.94]\n",
      " [1033.75]\n",
      " [1023.19]\n",
      " [1019.81]\n",
      " [ 997.15]\n",
      " [ 975.19]\n",
      " [ 981.65]\n",
      " [ 985.59]\n",
      " [ 947.24]\n",
      " [ 954.53]\n",
      " [ 941.04]\n",
      " [ 911.9 ]\n",
      " [ 942.9 ]\n",
      " [ 969.26]\n",
      " [ 969.33]\n",
      " [ 960.65]\n",
      " [ 952.12]\n",
      " [ 946.  ]\n",
      " [ 947.71]\n",
      " [ 971.46]\n",
      " [1005.69]\n",
      " [1032.16]\n",
      " [1048.42]\n",
      " [1036.28]\n",
      " [1080.01]\n",
      " [1093.67]\n",
      " [1048.69]\n",
      " [1041.02]\n",
      " [1050.53]\n",
      " [1051.81]\n",
      " [1032.07]\n",
      " [1047.45]\n",
      " [1050.43]\n",
      " [1055.32]\n",
      " [1052.48]\n",
      " [1038.4 ]\n",
      " [1023.13]\n",
      " [1018.88]\n",
      " [1022.61]\n",
      " [1020.34]\n",
      " [ 985.21]\n",
      " [1004.57]\n",
      " [1015.66]\n",
      " [1009.29]\n",
      " [1007.09]\n",
      " [1043.9 ]\n",
      " [1046.35]\n",
      " [1055.82]\n",
      " [1051.44]\n",
      " [1054.21]\n",
      " [1053.35]\n",
      " [1055.76]\n",
      " [1056.39]\n",
      " [1060.17]\n",
      " [1066.68]\n",
      " [1088.29]\n",
      " [1098.28]\n",
      " [1108.08]\n",
      " [1117.1 ]\n",
      " [1102.57]\n",
      " [1111.18]\n",
      " [1075.97]\n",
      " [1077.59]\n",
      " [1077.15]\n",
      " [1089.29]\n",
      " [1065.84]\n",
      " [1072.22]\n",
      " [1064.03]\n",
      " [1055.3 ]\n",
      " [1043.7 ]\n",
      " [1038.64]\n",
      " [1048.2 ]\n",
      " [1058.29]\n",
      " [1059.31]\n",
      " [1086.69]\n",
      " [1082.23]\n",
      " [1054.28]\n",
      " [1053.66]\n",
      " [1039.56]\n",
      " [1021.25]\n",
      " [1024.68]\n",
      " [1040.55]\n",
      " [1037.61]\n",
      " [1024.77]\n",
      " [1027.18]\n",
      " [1037.84]\n",
      " [1049.18]\n",
      " [1055.95]\n",
      " [1053.  ]\n",
      " [1052.8 ]\n",
      " [1040.13]\n",
      " [1062.19]\n",
      " [1047.4 ]\n",
      " [1045.14]\n",
      " [1023.1 ]\n",
      " [1032.43]\n",
      " [1040.54]\n",
      " [1045.1 ]\n",
      " [1046.79]\n",
      " [1052.25]\n",
      " [1054.29]\n",
      " [1056.33]\n",
      " [1059.44]\n",
      " [1064.64]\n",
      " [1079.28]\n",
      " [1078.45]\n",
      " [1080.86]\n",
      " [1070.91]\n",
      " [1069.71]\n",
      " [1065.35]\n",
      " [1069.46]\n",
      " [1069.45]\n",
      " [1064.3 ]\n",
      " [1052.89]\n",
      " [1053.81]\n",
      " [1055.02]\n",
      " [1048.98]\n",
      " [1049.25]\n",
      " [1042.91]\n",
      " [1041.36]\n",
      " [1034.85]\n",
      " [1040.8 ]\n",
      " [1039.63]\n",
      " [1049.12]\n",
      " [1040.61]\n",
      " [1040.31]\n",
      " [1053.44]\n",
      " [1053.77]\n",
      " [1058.26]\n",
      " [1057.12]\n",
      " [1066.9 ]\n",
      " [1065.71]\n",
      " [1065.91]\n",
      " [1060.44]\n",
      " [1068.31]\n",
      " [1067.07]\n",
      " [1070.64]\n",
      " [1065.85]\n",
      " [1061.79]\n",
      " [1064.63]\n",
      " [1063.76]\n",
      " [1074.98]\n",
      " [1078.05]\n",
      " [1075.17]\n",
      " [1078.39]\n",
      " [1090.84]\n",
      " [1097.82]\n",
      " [1108.31]\n",
      " [1109.54]\n",
      " [1101.32]\n",
      " [1107.53]]\n"
     ]
    }
   ],
   "source": [
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "# trainset = dataset_train.iloc[:,1:2].values\n",
    "print(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.92965443]\n",
      " [0.92456257]\n",
      " [0.8617575 ]\n",
      " [0.81353074]\n",
      " [0.86735207]\n",
      " [0.87724391]\n",
      " [0.90174648]\n",
      " [0.89454652]\n",
      " [0.91509235]\n",
      " [0.91478424]\n",
      " [0.91394101]\n",
      " [0.915741  ]\n",
      " [0.92089772]\n",
      " [0.91690856]\n",
      " [0.91919503]\n",
      " [0.91745991]\n",
      " [0.8838763 ]\n",
      " [0.91642207]\n",
      " [0.93563819]\n",
      " [0.94457327]\n",
      " [0.93067605]\n",
      " [0.93091929]\n",
      " [0.95088135]\n",
      " [0.99515138]\n",
      " [0.99015681]\n",
      " [1.        ]\n",
      " [0.99985405]\n",
      " [0.9596867 ]\n",
      " [0.94120032]\n",
      " [0.97071367]\n",
      " [0.94726515]\n",
      " [0.9472165 ]\n",
      " [0.87719526]\n",
      " [0.85465484]\n",
      " [0.86089805]\n",
      " [0.89740055]\n",
      " [0.9097086 ]\n",
      " [0.85590348]\n",
      " [0.92055719]\n",
      " [0.92380041]\n",
      " [0.90625456]\n",
      " [0.91955179]\n",
      " [0.94987595]\n",
      " [0.95527592]\n",
      " [0.9623948 ]\n",
      " [0.96468127]\n",
      " [0.95644348]\n",
      " [0.9082005 ]\n",
      " [0.94191383]\n",
      " [0.94085978]\n",
      " [0.96662721]\n",
      " [0.96151913]\n",
      " [0.9712488 ]\n",
      " [0.95929752]\n",
      " [0.97361636]\n",
      " [0.94531921]\n",
      " [0.95187053]\n",
      " [0.9376652 ]\n",
      " [0.95169215]\n",
      " [0.93018957]\n",
      " [0.96177858]\n",
      " [0.96231372]\n",
      " [0.95212999]\n",
      " [0.91103832]\n",
      " [0.91108697]\n",
      " [0.91974638]\n",
      " [0.89941135]\n",
      " [0.86650883]\n",
      " [0.8770331 ]\n",
      " [0.88771953]\n",
      " [0.89097897]\n",
      " [0.90356268]\n",
      " [0.94548138]\n",
      " [0.95980022]\n",
      " [0.95746509]\n",
      " [0.95084891]\n",
      " [0.9512381 ]\n",
      " [0.92639499]\n",
      " [0.95003811]\n",
      " [0.93828141]\n",
      " [0.94094086]\n",
      " [0.98032984]\n",
      " [0.99372436]\n",
      " [0.98615143]\n",
      " [0.99080546]\n",
      " [0.95748131]\n",
      " [0.92448149]\n",
      " [0.88110335]\n",
      " [0.91669775]\n",
      " [0.90845995]\n",
      " [0.88647088]\n",
      " [0.84437381]\n",
      " [0.80196864]\n",
      " [0.76673099]\n",
      " [0.74320139]\n",
      " [0.75782834]\n",
      " [0.64705596]\n",
      " [0.69638542]\n",
      " [0.71654207]\n",
      " [0.71203399]\n",
      " [0.73767169]\n",
      " [0.70828806]\n",
      " [0.72774742]\n",
      " [0.67679634]\n",
      " [0.58008335]\n",
      " [0.61890476]\n",
      " [0.63182902]\n",
      " [0.53017011]\n",
      " [0.43924627]\n",
      " [0.42170042]\n",
      " [0.51319182]\n",
      " [0.5332836 ]\n",
      " [0.53471062]\n",
      " [0.53320252]\n",
      " [0.4976892 ]\n",
      " [0.5213161 ]\n",
      " [0.57815363]\n",
      " [0.57838066]\n",
      " [0.60575348]\n",
      " [0.61948854]\n",
      " [0.61747774]\n",
      " [0.62856958]\n",
      " [0.610894  ]\n",
      " [0.60985616]\n",
      " [0.61314804]\n",
      " [0.615321  ]\n",
      " [0.64217491]\n",
      " [0.64199653]\n",
      " [0.60353187]\n",
      " [0.51103508]\n",
      " [0.51633775]\n",
      " [0.48977573]\n",
      " [0.52658634]\n",
      " [0.49524057]\n",
      " [0.43540305]\n",
      " [0.42254366]\n",
      " [0.4173545 ]\n",
      " [0.44915433]\n",
      " [0.44364085]\n",
      " [0.47175961]\n",
      " [0.49653786]\n",
      " [0.49652164]\n",
      " [0.46329479]\n",
      " [0.46540289]\n",
      " [0.45993805]\n",
      " [0.43684629]\n",
      " [0.38547359]\n",
      " [0.4128302 ]\n",
      " [0.42066259]\n",
      " [0.39468435]\n",
      " [0.42635445]\n",
      " [0.424895  ]\n",
      " [0.43827331]\n",
      " [0.4335382 ]\n",
      " [0.42906255]\n",
      " [0.43204631]\n",
      " [0.45768401]\n",
      " [0.4647056 ]\n",
      " [0.45868941]\n",
      " [0.44853812]\n",
      " [0.44297598]\n",
      " [0.45265701]\n",
      " [0.48035416]\n",
      " [0.47745147]\n",
      " [0.51802423]\n",
      " [0.53467819]\n",
      " [0.54787812]\n",
      " [0.554997  ]\n",
      " [0.55271053]\n",
      " [0.55921319]\n",
      " [0.56261858]\n",
      " [0.55880779]\n",
      " [0.55162405]\n",
      " [0.56826179]\n",
      " [0.58751034]\n",
      " [0.58830493]\n",
      " [0.58926168]\n",
      " [0.58663467]\n",
      " [0.57936984]\n",
      " [0.56518073]\n",
      " [0.58201307]\n",
      " [0.59231031]\n",
      " [0.61131561]\n",
      " [0.60108324]\n",
      " [0.58199685]\n",
      " [0.59592651]\n",
      " [0.59774271]\n",
      " [0.59261842]\n",
      " [0.5926995 ]\n",
      " [0.53719169]\n",
      " [0.52329447]\n",
      " [0.54628894]\n",
      " [0.54765109]\n",
      " [0.54567273]\n",
      " [0.53329982]\n",
      " [0.54122951]\n",
      " [0.52237015]\n",
      " [0.47599202]\n",
      " [0.4978838 ]\n",
      " [0.48429468]\n",
      " [0.49102437]\n",
      " [0.47250555]\n",
      " [0.42559229]\n",
      " [0.4129275 ]\n",
      " [0.37576013]\n",
      " [0.34730083]\n",
      " [0.35709537]\n",
      " [0.28303631]\n",
      " [0.26957692]\n",
      " [0.31193345]\n",
      " [0.26370668]\n",
      " [0.20109621]\n",
      " [0.21175021]\n",
      " [0.15291809]\n",
      " [0.19931244]\n",
      " [0.22555013]\n",
      " [0.24316085]\n",
      " [0.22650688]\n",
      " [0.24609597]\n",
      " [0.24027438]\n",
      " [0.23764736]\n",
      " [0.17500446]\n",
      " [0.12040475]\n",
      " [0.13913438]\n",
      " [0.13209658]\n",
      " [0.18828547]\n",
      " [0.18723142]\n",
      " [0.18817196]\n",
      " [0.19759353]\n",
      " [0.18046929]\n",
      " [0.17498824]\n",
      " [0.1382425 ]\n",
      " [0.10263188]\n",
      " [0.1131075 ]\n",
      " [0.11949665]\n",
      " [0.0573078 ]\n",
      " [0.06912936]\n",
      " [0.0472538 ]\n",
      " [0.        ]\n",
      " [0.05027   ]\n",
      " [0.09301571]\n",
      " [0.09312923]\n",
      " [0.07905363]\n",
      " [0.06522127]\n",
      " [0.055297  ]\n",
      " [0.05806996]\n",
      " [0.09658326]\n",
      " [0.15209107]\n",
      " [0.19501516]\n",
      " [0.22138259]\n",
      " [0.20169621]\n",
      " [0.27260934]\n",
      " [0.29476057]\n",
      " [0.22182042]\n",
      " [0.20938265]\n",
      " [0.22480419]\n",
      " [0.22687985]\n",
      " [0.19486922]\n",
      " [0.21980962]\n",
      " [0.22464203]\n",
      " [0.23257172]\n",
      " [0.22796634]\n",
      " [0.20513403]\n",
      " [0.180372  ]\n",
      " [0.17348014]\n",
      " [0.17952876]\n",
      " [0.1758477 ]\n",
      " [0.11888044]\n",
      " [0.15027486]\n",
      " [0.16825855]\n",
      " [0.15792888]\n",
      " [0.15436133]\n",
      " [0.2140529 ]\n",
      " [0.21802585]\n",
      " [0.23338252]\n",
      " [0.22627986]\n",
      " [0.23077173]\n",
      " [0.22937714]\n",
      " [0.23328523]\n",
      " [0.23430684]\n",
      " [0.24043654]\n",
      " [0.25099324]\n",
      " [0.28603629]\n",
      " [0.3022362 ]\n",
      " [0.31812801]\n",
      " [0.33275496]\n",
      " [0.30919292]\n",
      " [0.32315501]\n",
      " [0.26605802]\n",
      " [0.26868503]\n",
      " [0.26797152]\n",
      " [0.2876579 ]\n",
      " [0.24963108]\n",
      " [0.25997697]\n",
      " [0.24669596]\n",
      " [0.23253928]\n",
      " [0.21372857]\n",
      " [0.20552321]\n",
      " [0.22102583]\n",
      " [0.23738791]\n",
      " [0.23904195]\n",
      " [0.28344171]\n",
      " [0.27620932]\n",
      " [0.23088524]\n",
      " [0.22987984]\n",
      " [0.2070151 ]\n",
      " [0.17732337]\n",
      " [0.1828855 ]\n",
      " [0.20862049]\n",
      " [0.20385295]\n",
      " [0.18303144]\n",
      " [0.18693953]\n",
      " [0.20422592]\n",
      " [0.22261501]\n",
      " [0.23359333]\n",
      " [0.22880957]\n",
      " [0.22848525]\n",
      " [0.20793942]\n",
      " [0.2437122 ]\n",
      " [0.21972854]\n",
      " [0.2160637 ]\n",
      " [0.18032335]\n",
      " [0.195453  ]\n",
      " [0.20860428]\n",
      " [0.21599883]\n",
      " [0.21873936]\n",
      " [0.22759336]\n",
      " [0.23090145]\n",
      " [0.23420954]\n",
      " [0.23925276]\n",
      " [0.24768515]\n",
      " [0.27142556]\n",
      " [0.27007962]\n",
      " [0.27398771]\n",
      " [0.25785266]\n",
      " [0.25590672]\n",
      " [0.24883649]\n",
      " [0.25550132]\n",
      " [0.25548511]\n",
      " [0.2471338 ]\n",
      " [0.2286312 ]\n",
      " [0.23012308]\n",
      " [0.23208523]\n",
      " [0.22229069]\n",
      " [0.22272853]\n",
      " [0.2124475 ]\n",
      " [0.209934  ]\n",
      " [0.1993773 ]\n",
      " [0.2090259 ]\n",
      " [0.20712861]\n",
      " [0.22251772]\n",
      " [0.20871779]\n",
      " [0.20823131]\n",
      " [0.22952308]\n",
      " [0.23005822]\n",
      " [0.23733926]\n",
      " [0.23549062]\n",
      " [0.25134999]\n",
      " [0.24942027]\n",
      " [0.2497446 ]\n",
      " [0.24087437]\n",
      " [0.25363647]\n",
      " [0.25162567]\n",
      " [0.25741482]\n",
      " [0.2496473 ]\n",
      " [0.24306355]\n",
      " [0.24766893]\n",
      " [0.24625813]\n",
      " [0.26445262]\n",
      " [0.26943098]\n",
      " [0.26476073]\n",
      " [0.26998232]\n",
      " [0.2901714 ]\n",
      " [0.30149026]\n",
      " [0.31850098]\n",
      " [0.32049556]\n",
      " [0.30716591]\n",
      " [0.31723612]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "print(training_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368, 10) (368,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(10, 378):\n",
    "    x_train.append(training_scaled[i-10:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-30 10:30:15.260886: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 10ms/step - loss: 0.1611\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0357\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0190\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0098\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0092\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0093\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0097\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0078\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0086\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0086\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0082\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0088\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0070\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0076\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0075\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0086\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0086\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0090\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0086\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0077\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0071\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0088\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0078\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0081\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0067\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0071\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0071\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0078\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0069\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0064\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0062\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0071\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0073\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0069\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0066\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0060\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0064\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0067\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0075\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0073\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0071\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0070\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0072\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0060\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0061\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0064\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0061\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0059\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0062\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x286d9faf0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(LSTM(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(LSTM(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "regressor.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "regressor.fit(x_train, y_train, epochs = 50, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 10, 50)            10400     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10, 50)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 10, 50)            20200     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, 50)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 10, 50)            20200     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 10, 50)            0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71,051\n",
      "Trainable params: 71,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "result predict: [[1072.8501]]\n"
     ]
    }
   ],
   "source": [
    "data_test = [[\n",
    "    1074.98,\n",
    "    1078.05,\n",
    "    1075.17,\n",
    "    1078.39,\n",
    "    1090.84,\n",
    "    1097.82,\n",
    "    1108.31,\n",
    "    1109.54,\n",
    "    1101.32,\n",
    "    1107.53,\n",
    "]]\n",
    "\n",
    "def convert_to_predict(data):\n",
    "    new_data = []\n",
    "    for i in range(0, len(data)):\n",
    "        item = np.array(data[i]).reshape(-1,1)\n",
    "        item = sc.transform(item)\n",
    "        new_data.append(item)\n",
    "    new_data = np.array(new_data)\n",
    "    new_data = np.reshape(new_data, (new_data.shape[0], new_data.shape[1], 1))\n",
    "    return new_data\n",
    "\n",
    "def predict(data):\n",
    "    raw_transform_data = convert_to_predict(data)\n",
    "    result = regressor.predict(raw_transform_data)\n",
    "    predicted_price = sc.inverse_transform(result)\n",
    "    return predicted_price\n",
    "\n",
    "result = predict(data_test)\n",
    "print('result predict:', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
